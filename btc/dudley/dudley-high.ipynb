{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b0bfb3-96d6-48cc-b261-6ed2924aad11",
   "metadata": {},
   "source": [
    "# Dudley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98425636-8a8b-421f-afd8-68dccc65159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9da0bc-1413-4bcd-8b51-9286d86fdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"amalgamated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c9cd48-db18-40fa-bbdc-d20473815d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"BTC-USD_High\",\n",
    "    \"BTC-USD_Low\",\n",
    "    \"AdrBalNtv0.01Cnt\",\n",
    "    \"AdrBalNtv0.1Cnt\",\n",
    "    \"AdrBalNtv1Cnt\",\n",
    "    \"AdrBalNtv10Cnt\",\n",
    "    \"BlkSizeMeanByte\",\n",
    "    \"CapRealUSD\",\n",
    "    \"FeeByteMeanNtv\",\n",
    "    \"FlowInExNtv\",\n",
    "    \"FlowOutExNtv\",\n",
    "    \"FlowTfrFromExCnt\",\n",
    "    \"HashRate\",\n",
    "    \"NDF\",\n",
    "    \"SplyAct1d\",\n",
    "    \"SplyActPct1yr\",\n",
    "    \"TxCnt\",\n",
    "    \"VelCur1yr\",\n",
    "    'SPY_High',\n",
    "    'SPY_Low',\n",
    "    'QQQ_High',\n",
    "    'QQQ_Low',\n",
    "    '^IRX_High',\n",
    "    '^IRX_Low',\n",
    "    '^TNX_High',\n",
    "    '^TNX_Low',\n",
    "    '^TYX_High',\n",
    "    '^TYX_Low',\n",
    "    'Global_Liquidity_Index',\n",
    "    'BTC-USD_High_SMA_5',\n",
    "    'BTC-USD_Low_SMA_5',\n",
    "    'BTC-USD_High_SMA_10',\n",
    "    'BTC-USD_Low_SMA_10',\n",
    "    'BTC-USD_High_SMA_20',\n",
    "    'BTC-USD_Low_SMA_20',\n",
    "    'BTC-USD_High_SMA_50',\n",
    "    'BTC-USD_Low_SMA_50',\n",
    "    'BTC-USD_High_SMA_100',\n",
    "    'BTC-USD_Low_SMA_100'\n",
    "]\n",
    "\n",
    "df = df[vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5001d85-6388-4d46-b27b-36b8d6ae11d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_High</th>\n",
       "      <th>BTC-USD_Low</th>\n",
       "      <th>AdrBalNtv0.01Cnt</th>\n",
       "      <th>AdrBalNtv0.1Cnt</th>\n",
       "      <th>AdrBalNtv1Cnt</th>\n",
       "      <th>AdrBalNtv10Cnt</th>\n",
       "      <th>BlkSizeMeanByte</th>\n",
       "      <th>CapRealUSD</th>\n",
       "      <th>FeeByteMeanNtv</th>\n",
       "      <th>FlowInExNtv</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC-USD_High_SMA_5</th>\n",
       "      <th>BTC-USD_Low_SMA_5</th>\n",
       "      <th>BTC-USD_High_SMA_10</th>\n",
       "      <th>BTC-USD_Low_SMA_10</th>\n",
       "      <th>BTC-USD_High_SMA_20</th>\n",
       "      <th>BTC-USD_Low_SMA_20</th>\n",
       "      <th>BTC-USD_High_SMA_50</th>\n",
       "      <th>BTC-USD_Low_SMA_50</th>\n",
       "      <th>BTC-USD_High_SMA_100</th>\n",
       "      <th>BTC-USD_Low_SMA_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-16</th>\n",
       "      <td>773.721985</td>\n",
       "      <td>696.523010</td>\n",
       "      <td>2707487.0</td>\n",
       "      <td>1194210.0</td>\n",
       "      <td>486235.0</td>\n",
       "      <td>138918.0</td>\n",
       "      <td>9.576345e+05</td>\n",
       "      <td>5.504034e+09</td>\n",
       "      <td>5.800000e-07</td>\n",
       "      <td>103461.872142</td>\n",
       "      <td>...</td>\n",
       "      <td>715.075403</td>\n",
       "      <td>660.682800</td>\n",
       "      <td>651.692102</td>\n",
       "      <td>616.700800</td>\n",
       "      <td>605.640051</td>\n",
       "      <td>574.958147</td>\n",
       "      <td>514.898219</td>\n",
       "      <td>498.599160</td>\n",
       "      <td>471.263739</td>\n",
       "      <td>460.382540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17</th>\n",
       "      <td>775.356018</td>\n",
       "      <td>716.556030</td>\n",
       "      <td>2697438.0</td>\n",
       "      <td>1194425.0</td>\n",
       "      <td>485785.0</td>\n",
       "      <td>138762.0</td>\n",
       "      <td>9.202532e+05</td>\n",
       "      <td>5.528068e+09</td>\n",
       "      <td>5.700000e-07</td>\n",
       "      <td>101196.210866</td>\n",
       "      <td>...</td>\n",
       "      <td>733.177808</td>\n",
       "      <td>682.586206</td>\n",
       "      <td>670.201807</td>\n",
       "      <td>631.605005</td>\n",
       "      <td>617.734201</td>\n",
       "      <td>587.150998</td>\n",
       "      <td>521.414319</td>\n",
       "      <td>504.197281</td>\n",
       "      <td>474.856979</td>\n",
       "      <td>463.432041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18</th>\n",
       "      <td>777.989990</td>\n",
       "      <td>733.929016</td>\n",
       "      <td>2700495.0</td>\n",
       "      <td>1195493.0</td>\n",
       "      <td>486147.0</td>\n",
       "      <td>138745.0</td>\n",
       "      <td>8.705890e+05</td>\n",
       "      <td>5.549665e+09</td>\n",
       "      <td>5.200000e-07</td>\n",
       "      <td>71224.258522</td>\n",
       "      <td>...</td>\n",
       "      <td>745.575000</td>\n",
       "      <td>696.474609</td>\n",
       "      <td>689.716907</td>\n",
       "      <td>647.684906</td>\n",
       "      <td>628.935699</td>\n",
       "      <td>598.238498</td>\n",
       "      <td>527.866439</td>\n",
       "      <td>509.955521</td>\n",
       "      <td>478.461759</td>\n",
       "      <td>466.638821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19</th>\n",
       "      <td>766.620972</td>\n",
       "      <td>745.627991</td>\n",
       "      <td>2698863.0</td>\n",
       "      <td>1193758.0</td>\n",
       "      <td>486101.0</td>\n",
       "      <td>138807.0</td>\n",
       "      <td>7.119917e+05</td>\n",
       "      <td>5.566891e+09</td>\n",
       "      <td>4.900000e-07</td>\n",
       "      <td>44574.581631</td>\n",
       "      <td>...</td>\n",
       "      <td>757.998389</td>\n",
       "      <td>713.039404</td>\n",
       "      <td>708.158704</td>\n",
       "      <td>665.152606</td>\n",
       "      <td>640.049298</td>\n",
       "      <td>609.371747</td>\n",
       "      <td>534.087119</td>\n",
       "      <td>515.914141</td>\n",
       "      <td>481.888709</td>\n",
       "      <td>469.924971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20</th>\n",
       "      <td>764.083984</td>\n",
       "      <td>732.726990</td>\n",
       "      <td>2707494.0</td>\n",
       "      <td>1197120.0</td>\n",
       "      <td>487506.0</td>\n",
       "      <td>138842.0</td>\n",
       "      <td>7.968285e+05</td>\n",
       "      <td>5.573669e+09</td>\n",
       "      <td>5.900000e-07</td>\n",
       "      <td>75586.050007</td>\n",
       "      <td>...</td>\n",
       "      <td>771.554590</td>\n",
       "      <td>725.072607</td>\n",
       "      <td>726.654401</td>\n",
       "      <td>681.092804</td>\n",
       "      <td>650.922598</td>\n",
       "      <td>619.974997</td>\n",
       "      <td>540.319218</td>\n",
       "      <td>521.610141</td>\n",
       "      <td>485.311599</td>\n",
       "      <td>473.151301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>43243.167969</td>\n",
       "      <td>41879.191406</td>\n",
       "      <td>12619292.0</td>\n",
       "      <td>4572236.0</td>\n",
       "      <td>1019807.0</td>\n",
       "      <td>154559.0</td>\n",
       "      <td>1.706556e+06</td>\n",
       "      <td>4.479779e+11</td>\n",
       "      <td>2.166770e-07</td>\n",
       "      <td>28549.993968</td>\n",
       "      <td>...</td>\n",
       "      <td>43380.512500</td>\n",
       "      <td>42080.950000</td>\n",
       "      <td>42217.319922</td>\n",
       "      <td>40923.807813</td>\n",
       "      <td>42447.216016</td>\n",
       "      <td>41136.506836</td>\n",
       "      <td>43648.887969</td>\n",
       "      <td>42018.851875</td>\n",
       "      <td>40943.784688</td>\n",
       "      <td>39519.390898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-02</th>\n",
       "      <td>43422.488281</td>\n",
       "      <td>42584.335938</td>\n",
       "      <td>12618955.0</td>\n",
       "      <td>4571607.0</td>\n",
       "      <td>1019919.0</td>\n",
       "      <td>154576.0</td>\n",
       "      <td>1.700535e+06</td>\n",
       "      <td>4.482718e+11</td>\n",
       "      <td>2.066230e-07</td>\n",
       "      <td>26037.366846</td>\n",
       "      <td>...</td>\n",
       "      <td>43505.575000</td>\n",
       "      <td>42258.435156</td>\n",
       "      <td>42546.833594</td>\n",
       "      <td>41330.051953</td>\n",
       "      <td>42456.607422</td>\n",
       "      <td>41142.516406</td>\n",
       "      <td>43649.520547</td>\n",
       "      <td>42035.196797</td>\n",
       "      <td>41026.671992</td>\n",
       "      <td>39608.143164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-03</th>\n",
       "      <td>43359.941406</td>\n",
       "      <td>42890.808594</td>\n",
       "      <td>12623419.0</td>\n",
       "      <td>4572105.0</td>\n",
       "      <td>1019723.0</td>\n",
       "      <td>154548.0</td>\n",
       "      <td>1.696869e+06</td>\n",
       "      <td>4.483556e+11</td>\n",
       "      <td>7.011070e-07</td>\n",
       "      <td>14200.160578</td>\n",
       "      <td>...</td>\n",
       "      <td>43516.389844</td>\n",
       "      <td>42472.930469</td>\n",
       "      <td>42834.449219</td>\n",
       "      <td>41668.253125</td>\n",
       "      <td>42471.324609</td>\n",
       "      <td>41200.826172</td>\n",
       "      <td>43654.962891</td>\n",
       "      <td>42059.153594</td>\n",
       "      <td>41111.942305</td>\n",
       "      <td>39699.428008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-04</th>\n",
       "      <td>43097.644531</td>\n",
       "      <td>42374.832031</td>\n",
       "      <td>12612131.0</td>\n",
       "      <td>4571390.0</td>\n",
       "      <td>1019829.0</td>\n",
       "      <td>154504.0</td>\n",
       "      <td>1.576919e+06</td>\n",
       "      <td>4.484874e+11</td>\n",
       "      <td>3.948680e-07</td>\n",
       "      <td>14806.864074</td>\n",
       "      <td>...</td>\n",
       "      <td>43368.129687</td>\n",
       "      <td>42405.622656</td>\n",
       "      <td>43118.765625</td>\n",
       "      <td>41951.169922</td>\n",
       "      <td>42460.220703</td>\n",
       "      <td>41234.296875</td>\n",
       "      <td>43663.616875</td>\n",
       "      <td>42072.187969</td>\n",
       "      <td>41200.536641</td>\n",
       "      <td>39789.007461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-05</th>\n",
       "      <td>43494.250000</td>\n",
       "      <td>42264.816406</td>\n",
       "      <td>12605783.0</td>\n",
       "      <td>4571143.0</td>\n",
       "      <td>1019671.0</td>\n",
       "      <td>154513.0</td>\n",
       "      <td>1.415660e+06</td>\n",
       "      <td>4.487452e+11</td>\n",
       "      <td>2.925980e-07</td>\n",
       "      <td>23439.165199</td>\n",
       "      <td>...</td>\n",
       "      <td>43323.498437</td>\n",
       "      <td>42398.796875</td>\n",
       "      <td>43247.251953</td>\n",
       "      <td>42195.082422</td>\n",
       "      <td>42456.619531</td>\n",
       "      <td>41243.237891</td>\n",
       "      <td>43686.311953</td>\n",
       "      <td>42091.993438</td>\n",
       "      <td>41291.485234</td>\n",
       "      <td>39872.907578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2791 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_High   BTC-USD_Low  AdrBalNtv0.01Cnt  AdrBalNtv0.1Cnt  \\\n",
       "2016-06-16    773.721985    696.523010         2707487.0        1194210.0   \n",
       "2016-06-17    775.356018    716.556030         2697438.0        1194425.0   \n",
       "2016-06-18    777.989990    733.929016         2700495.0        1195493.0   \n",
       "2016-06-19    766.620972    745.627991         2698863.0        1193758.0   \n",
       "2016-06-20    764.083984    732.726990         2707494.0        1197120.0   \n",
       "...                  ...           ...               ...              ...   \n",
       "2024-02-01  43243.167969  41879.191406        12619292.0        4572236.0   \n",
       "2024-02-02  43422.488281  42584.335938        12618955.0        4571607.0   \n",
       "2024-02-03  43359.941406  42890.808594        12623419.0        4572105.0   \n",
       "2024-02-04  43097.644531  42374.832031        12612131.0        4571390.0   \n",
       "2024-02-05  43494.250000  42264.816406        12605783.0        4571143.0   \n",
       "\n",
       "            AdrBalNtv1Cnt  AdrBalNtv10Cnt  BlkSizeMeanByte    CapRealUSD  \\\n",
       "2016-06-16       486235.0        138918.0     9.576345e+05  5.504034e+09   \n",
       "2016-06-17       485785.0        138762.0     9.202532e+05  5.528068e+09   \n",
       "2016-06-18       486147.0        138745.0     8.705890e+05  5.549665e+09   \n",
       "2016-06-19       486101.0        138807.0     7.119917e+05  5.566891e+09   \n",
       "2016-06-20       487506.0        138842.0     7.968285e+05  5.573669e+09   \n",
       "...                   ...             ...              ...           ...   \n",
       "2024-02-01      1019807.0        154559.0     1.706556e+06  4.479779e+11   \n",
       "2024-02-02      1019919.0        154576.0     1.700535e+06  4.482718e+11   \n",
       "2024-02-03      1019723.0        154548.0     1.696869e+06  4.483556e+11   \n",
       "2024-02-04      1019829.0        154504.0     1.576919e+06  4.484874e+11   \n",
       "2024-02-05      1019671.0        154513.0     1.415660e+06  4.487452e+11   \n",
       "\n",
       "            FeeByteMeanNtv    FlowInExNtv  ...  BTC-USD_High_SMA_5  \\\n",
       "2016-06-16    5.800000e-07  103461.872142  ...          715.075403   \n",
       "2016-06-17    5.700000e-07  101196.210866  ...          733.177808   \n",
       "2016-06-18    5.200000e-07   71224.258522  ...          745.575000   \n",
       "2016-06-19    4.900000e-07   44574.581631  ...          757.998389   \n",
       "2016-06-20    5.900000e-07   75586.050007  ...          771.554590   \n",
       "...                    ...            ...  ...                 ...   \n",
       "2024-02-01    2.166770e-07   28549.993968  ...        43380.512500   \n",
       "2024-02-02    2.066230e-07   26037.366846  ...        43505.575000   \n",
       "2024-02-03    7.011070e-07   14200.160578  ...        43516.389844   \n",
       "2024-02-04    3.948680e-07   14806.864074  ...        43368.129687   \n",
       "2024-02-05    2.925980e-07   23439.165199  ...        43323.498437   \n",
       "\n",
       "            BTC-USD_Low_SMA_5  BTC-USD_High_SMA_10  BTC-USD_Low_SMA_10  \\\n",
       "2016-06-16         660.682800           651.692102          616.700800   \n",
       "2016-06-17         682.586206           670.201807          631.605005   \n",
       "2016-06-18         696.474609           689.716907          647.684906   \n",
       "2016-06-19         713.039404           708.158704          665.152606   \n",
       "2016-06-20         725.072607           726.654401          681.092804   \n",
       "...                       ...                  ...                 ...   \n",
       "2024-02-01       42080.950000         42217.319922        40923.807813   \n",
       "2024-02-02       42258.435156         42546.833594        41330.051953   \n",
       "2024-02-03       42472.930469         42834.449219        41668.253125   \n",
       "2024-02-04       42405.622656         43118.765625        41951.169922   \n",
       "2024-02-05       42398.796875         43247.251953        42195.082422   \n",
       "\n",
       "            BTC-USD_High_SMA_20  BTC-USD_Low_SMA_20  BTC-USD_High_SMA_50  \\\n",
       "2016-06-16           605.640051          574.958147           514.898219   \n",
       "2016-06-17           617.734201          587.150998           521.414319   \n",
       "2016-06-18           628.935699          598.238498           527.866439   \n",
       "2016-06-19           640.049298          609.371747           534.087119   \n",
       "2016-06-20           650.922598          619.974997           540.319218   \n",
       "...                         ...                 ...                  ...   \n",
       "2024-02-01         42447.216016        41136.506836         43648.887969   \n",
       "2024-02-02         42456.607422        41142.516406         43649.520547   \n",
       "2024-02-03         42471.324609        41200.826172         43654.962891   \n",
       "2024-02-04         42460.220703        41234.296875         43663.616875   \n",
       "2024-02-05         42456.619531        41243.237891         43686.311953   \n",
       "\n",
       "            BTC-USD_Low_SMA_50  BTC-USD_High_SMA_100  BTC-USD_Low_SMA_100  \n",
       "2016-06-16          498.599160            471.263739           460.382540  \n",
       "2016-06-17          504.197281            474.856979           463.432041  \n",
       "2016-06-18          509.955521            478.461759           466.638821  \n",
       "2016-06-19          515.914141            481.888709           469.924971  \n",
       "2016-06-20          521.610141            485.311599           473.151301  \n",
       "...                        ...                   ...                  ...  \n",
       "2024-02-01        42018.851875          40943.784688         39519.390898  \n",
       "2024-02-02        42035.196797          41026.671992         39608.143164  \n",
       "2024-02-03        42059.153594          41111.942305         39699.428008  \n",
       "2024-02-04        42072.187969          41200.536641         39789.007461  \n",
       "2024-02-05        42091.993438          41291.485234         39872.907578  \n",
       "\n",
       "[2791 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "#df = df.pct_change()*100\n",
    "\n",
    "# The first row will be NaN because there's no previous data to subtract from the first entry\n",
    "# If you wish to remove the NaN values, you can drop the first row\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1f40562-edc0-4a3a-94cf-d5a16f17ead5",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame and 'BTC-USD_High' is the column of interest\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['BTC-USD_High'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of BTC-USD High Values - Histogram')\n",
    "plt.xlabel('BTC-USD High')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# KDE Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df['BTC-USD_High'], fill=True)\n",
    "plt.title('Distribution of BTC-USD High Values - KDE Plot')\n",
    "plt.xlabel('BTC-USD High')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8ae61c-85c4-4789-93c6-e473fb853a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type                           | Params | In sizes                                                                      | Out sizes\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 307 M  | [[1, 7], [1, 7], [1, 1], [1, 1], [1, 8, 3], [1, 8, 0], [1, 7, 38], [1, 7, 0]] | [1, 3, 1]\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "307 M     Trainable params\n",
      "0         Non-trainable params\n",
      "307 M     Total params\n",
      "1,230.034 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401eb82657894e39a426ca02ca6e32d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 100: 'train_loss' reached 1789.06934 (best 1789.06934), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=0-step=100.ckpt' as top 1\n",
      "Epoch 1, global step 200: 'train_loss' reached 911.68573 (best 911.68573), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=1-step=200.ckpt' as top 1\n",
      "Epoch 2, global step 300: 'train_loss' reached 871.73065 (best 871.73065), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=2-step=300.ckpt' as top 1\n",
      "Epoch 3, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 500: 'train_loss' reached 857.95795 (best 857.95795), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=4-step=500.ckpt' as top 1\n",
      "Epoch 5, global step 600: 'train_loss' reached 854.67969 (best 854.67969), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=5-step=600.ckpt' as top 1\n",
      "Epoch 6, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 800: 'train_loss' reached 842.36078 (best 842.36078), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=7-step=800.ckpt' as top 1\n",
      "Epoch 8, global step 900: 'train_loss' reached 801.24701 (best 801.24701), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=8-step=900.ckpt' as top 1\n",
      "Epoch 9, global step 1000: 'train_loss' reached 773.36542 (best 773.36542), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=9-step=1000.ckpt' as top 1\n",
      "Epoch 10, global step 1100: 'train_loss' reached 768.54297 (best 768.54297), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=10-step=1100.ckpt' as top 1\n",
      "Epoch 11, global step 1200: 'train_loss' reached 725.88708 (best 725.88708), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=11-step=1200.ckpt' as top 1\n",
      "Epoch 12, global step 1300: 'train_loss' reached 685.76331 (best 685.76331), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=12-step=1300.ckpt' as top 1\n",
      "Epoch 13, global step 1400: 'train_loss' reached 658.60327 (best 658.60327), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=13-step=1400.ckpt' as top 1\n",
      "Epoch 14, global step 1500: 'train_loss' reached 595.78845 (best 595.78845), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=14-step=1500.ckpt' as top 1\n",
      "Epoch 15, global step 1600: 'train_loss' reached 566.32153 (best 566.32153), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=15-step=1600.ckpt' as top 1\n",
      "Epoch 16, global step 1700: 'train_loss' reached 494.72479 (best 494.72479), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=16-step=1700.ckpt' as top 1\n",
      "Epoch 17, global step 1800: 'train_loss' reached 441.35803 (best 441.35803), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=17-step=1800.ckpt' as top 1\n",
      "Epoch 18, global step 1900: 'train_loss' reached 381.82703 (best 381.82703), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=18-step=1900.ckpt' as top 1\n",
      "Epoch 19, global step 2000: 'train_loss' reached 369.13245 (best 369.13245), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=19-step=2000.ckpt' as top 1\n",
      "Epoch 20, global step 2100: 'train_loss' reached 346.63223 (best 346.63223), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=20-step=2100.ckpt' as top 1\n",
      "Epoch 21, global step 2200: 'train_loss' reached 306.46796 (best 306.46796), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=21-step=2200.ckpt' as top 1\n",
      "Epoch 22, global step 2300: 'train_loss' reached 269.47034 (best 269.47034), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=22-step=2300.ckpt' as top 1\n",
      "Epoch 23, global step 2400: 'train_loss' reached 233.53844 (best 233.53844), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=23-step=2400.ckpt' as top 1\n",
      "Epoch 24, global step 2500: 'train_loss' reached 225.25883 (best 225.25883), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=24-step=2500.ckpt' as top 1\n",
      "Epoch 25, global step 2600: 'train_loss' reached 217.02078 (best 217.02078), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=25-step=2600.ckpt' as top 1\n",
      "Epoch 26, global step 2700: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 2800: 'train_loss' reached 208.09578 (best 208.09578), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=27-step=2800.ckpt' as top 1\n",
      "Epoch 28, global step 2900: 'train_loss' reached 184.43547 (best 184.43547), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=28-step=2900.ckpt' as top 1\n",
      "Epoch 29, global step 3000: 'train_loss' reached 164.93346 (best 164.93346), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=29-step=3000.ckpt' as top 1\n",
      "Epoch 30, global step 3100: 'train_loss' reached 150.52818 (best 150.52818), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=30-step=3100.ckpt' as top 1\n",
      "Epoch 31, global step 3200: 'train_loss' reached 143.57964 (best 143.57964), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=31-step=3200.ckpt' as top 1\n",
      "Epoch 32, global step 3300: 'train_loss' reached 130.67998 (best 130.67998), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=32-step=3300.ckpt' as top 1\n",
      "Epoch 33, global step 3400: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 3500: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 3600: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 3700: 'train_loss' reached 129.00322 (best 129.00322), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=36-step=3700.ckpt' as top 1\n",
      "Epoch 37, global step 3800: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 3900: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 4000: 'train_loss' reached 124.39429 (best 124.39429), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=39-step=4000.ckpt' as top 1\n",
      "Epoch 40, global step 4100: 'train_loss' reached 120.47061 (best 120.47061), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=40-step=4100.ckpt' as top 1\n",
      "Epoch 41, global step 4200: 'train_loss' reached 110.06136 (best 110.06136), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=41-step=4200.ckpt' as top 1\n",
      "Epoch 42, global step 4300: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 4400: 'train_loss' reached 102.35435 (best 102.35435), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=43-step=4400.ckpt' as top 1\n",
      "Epoch 44, global step 4500: 'train_loss' reached 93.18618 (best 93.18618), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=44-step=4500.ckpt' as top 1\n",
      "Epoch 45, global step 4600: 'train_loss' reached 83.00150 (best 83.00150), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=45-step=4600.ckpt' as top 1\n",
      "Epoch 46, global step 4700: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 4800: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 4900: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 5000: 'train_loss' reached 78.89497 (best 78.89497), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=49-step=5000.ckpt' as top 1\n",
      "Epoch 50, global step 5100: 'train_loss' was not in top 1\n",
      "Epoch 51, global step 5200: 'train_loss' was not in top 1\n",
      "Epoch 52, global step 5300: 'train_loss' was not in top 1\n",
      "Epoch 53, global step 5400: 'train_loss' reached 74.55925 (best 74.55925), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=53-step=5400.ckpt' as top 1\n",
      "Epoch 54, global step 5500: 'train_loss' was not in top 1\n",
      "Epoch 55, global step 5600: 'train_loss' was not in top 1\n",
      "Epoch 56, global step 5700: 'train_loss' reached 70.03596 (best 70.03596), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=56-step=5700.ckpt' as top 1\n",
      "Epoch 57, global step 5800: 'train_loss' reached 69.65075 (best 69.65075), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=57-step=5800.ckpt' as top 1\n",
      "Epoch 58, global step 5900: 'train_loss' reached 66.97583 (best 66.97583), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=58-step=5900.ckpt' as top 1\n",
      "Epoch 59, global step 6000: 'train_loss' was not in top 1\n",
      "Epoch 60, global step 6100: 'train_loss' was not in top 1\n",
      "Epoch 61, global step 6200: 'train_loss' was not in top 1\n",
      "Epoch 62, global step 6300: 'train_loss' was not in top 1\n",
      "Epoch 63, global step 6400: 'train_loss' reached 63.93988 (best 63.93988), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=63-step=6400.ckpt' as top 1\n",
      "Epoch 64, global step 6500: 'train_loss' reached 60.62163 (best 60.62163), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=64-step=6500.ckpt' as top 1\n",
      "Epoch 65, global step 6600: 'train_loss' reached 59.85692 (best 59.85692), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=65-step=6600.ckpt' as top 1\n",
      "Epoch 66, global step 6700: 'train_loss' reached 58.38589 (best 58.38589), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=66-step=6700.ckpt' as top 1\n",
      "Epoch 67, global step 6800: 'train_loss' was not in top 1\n",
      "Epoch 68, global step 6900: 'train_loss' was not in top 1\n",
      "Epoch 69, global step 7000: 'train_loss' was not in top 1\n",
      "Epoch 70, global step 7100: 'train_loss' was not in top 1\n",
      "Epoch 71, global step 7200: 'train_loss' reached 56.24960 (best 56.24960), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=71-step=7200.ckpt' as top 1\n",
      "Epoch 72, global step 7300: 'train_loss' was not in top 1\n",
      "Epoch 73, global step 7400: 'train_loss' reached 48.05512 (best 48.05512), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=73-step=7400.ckpt' as top 1\n",
      "Epoch 74, global step 7500: 'train_loss' was not in top 1\n",
      "Epoch 75, global step 7600: 'train_loss' reached 47.73610 (best 47.73610), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=75-step=7600.ckpt' as top 1\n",
      "Epoch 76, global step 7700: 'train_loss' was not in top 1\n",
      "Epoch 77, global step 7800: 'train_loss' was not in top 1\n",
      "Epoch 78, global step 7900: 'train_loss' reached 45.65977 (best 45.65977), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=78-step=7900.ckpt' as top 1\n",
      "Epoch 79, global step 8000: 'train_loss' was not in top 1\n",
      "Epoch 80, global step 8100: 'train_loss' reached 43.36197 (best 43.36197), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=80-step=8100.ckpt' as top 1\n",
      "Epoch 81, global step 8200: 'train_loss' was not in top 1\n",
      "Epoch 82, global step 8300: 'train_loss' reached 38.09966 (best 38.09966), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=82-step=8300.ckpt' as top 1\n",
      "Epoch 83, global step 8400: 'train_loss' was not in top 1\n",
      "Epoch 84, global step 8500: 'train_loss' was not in top 1\n",
      "Epoch 85, global step 8600: 'train_loss' was not in top 1\n",
      "Epoch 86, global step 8700: 'train_loss' reached 37.60649 (best 37.60649), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=86-step=8700.ckpt' as top 1\n",
      "Epoch 87, global step 8800: 'train_loss' reached 34.22374 (best 34.22374), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=87-step=8800.ckpt' as top 1\n",
      "Epoch 88, global step 8900: 'train_loss' was not in top 1\n",
      "Epoch 89, global step 9000: 'train_loss' reached 33.71316 (best 33.71316), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=89-step=9000.ckpt' as top 1\n",
      "Epoch 90, global step 9100: 'train_loss' was not in top 1\n",
      "Epoch 91, global step 9200: 'train_loss' was not in top 1\n",
      "Epoch 92, global step 9300: 'train_loss' was not in top 1\n",
      "Epoch 93, global step 9400: 'train_loss' reached 33.66295 (best 33.66295), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=93-step=9400.ckpt' as top 1\n",
      "Epoch 94, global step 9500: 'train_loss' was not in top 1\n",
      "Epoch 95, global step 9600: 'train_loss' was not in top 1\n",
      "Epoch 96, global step 9700: 'train_loss' reached 31.45455 (best 31.45455), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=96-step=9700.ckpt' as top 1\n",
      "Epoch 97, global step 9800: 'train_loss' was not in top 1\n",
      "Epoch 98, global step 9900: 'train_loss' reached 30.29626 (best 30.29626), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=98-step=9900.ckpt' as top 1\n",
      "Epoch 99, global step 10000: 'train_loss' reached 29.53782 (best 29.53782), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=99-step=10000.ckpt' as top 1\n",
      "Epoch 100, global step 10100: 'train_loss' was not in top 1\n",
      "Epoch 101, global step 10200: 'train_loss' was not in top 1\n",
      "Epoch 102, global step 10300: 'train_loss' was not in top 1\n",
      "Epoch 103, global step 10400: 'train_loss' was not in top 1\n",
      "Epoch 104, global step 10500: 'train_loss' was not in top 1\n",
      "Epoch 105, global step 10600: 'train_loss' reached 28.96132 (best 28.96132), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=105-step=10600.ckpt' as top 1\n",
      "Epoch 106, global step 10700: 'train_loss' reached 28.46777 (best 28.46777), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=106-step=10700.ckpt' as top 1\n",
      "Epoch 107, global step 10800: 'train_loss' reached 26.76680 (best 26.76680), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=107-step=10800.ckpt' as top 1\n",
      "Epoch 108, global step 10900: 'train_loss' reached 25.19493 (best 25.19493), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=108-step=10900.ckpt' as top 1\n",
      "Epoch 109, global step 11000: 'train_loss' reached 23.34945 (best 23.34945), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=109-step=11000.ckpt' as top 1\n",
      "Epoch 110, global step 11100: 'train_loss' was not in top 1\n",
      "Epoch 111, global step 11200: 'train_loss' was not in top 1\n",
      "Epoch 112, global step 11300: 'train_loss' reached 22.22512 (best 22.22512), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=112-step=11300.ckpt' as top 1\n",
      "Epoch 113, global step 11400: 'train_loss' was not in top 1\n",
      "Epoch 114, global step 11500: 'train_loss' was not in top 1\n",
      "Epoch 115, global step 11600: 'train_loss' was not in top 1\n",
      "Epoch 116, global step 11700: 'train_loss' was not in top 1\n",
      "Epoch 117, global step 11800: 'train_loss' was not in top 1\n",
      "Epoch 118, global step 11900: 'train_loss' was not in top 1\n",
      "Epoch 119, global step 12000: 'train_loss' was not in top 1\n",
      "Epoch 120, global step 12100: 'train_loss' was not in top 1\n",
      "Epoch 121, global step 12200: 'train_loss' reached 21.81429 (best 21.81429), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=121-step=12200.ckpt' as top 1\n",
      "Epoch 122, global step 12300: 'train_loss' reached 20.87022 (best 20.87022), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=122-step=12300.ckpt' as top 1\n",
      "Epoch 123, global step 12400: 'train_loss' reached 20.32254 (best 20.32254), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=123-step=12400.ckpt' as top 1\n",
      "Epoch 124, global step 12500: 'train_loss' was not in top 1\n",
      "Epoch 125, global step 12600: 'train_loss' was not in top 1\n",
      "Epoch 126, global step 12700: 'train_loss' was not in top 1\n",
      "Epoch 127, global step 12800: 'train_loss' was not in top 1\n",
      "Epoch 128, global step 12900: 'train_loss' reached 20.12652 (best 20.12652), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=128-step=12900.ckpt' as top 1\n",
      "Epoch 129, global step 13000: 'train_loss' was not in top 1\n",
      "Epoch 130, global step 13100: 'train_loss' reached 18.46709 (best 18.46709), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=130-step=13100.ckpt' as top 1\n",
      "Epoch 131, global step 13200: 'train_loss' was not in top 1\n",
      "Epoch 132, global step 13300: 'train_loss' was not in top 1\n",
      "Epoch 133, global step 13400: 'train_loss' was not in top 1\n",
      "Epoch 134, global step 13500: 'train_loss' was not in top 1\n",
      "Epoch 135, global step 13600: 'train_loss' was not in top 1\n",
      "Epoch 136, global step 13700: 'train_loss' was not in top 1\n",
      "Epoch 137, global step 13800: 'train_loss' was not in top 1\n",
      "Epoch 138, global step 13900: 'train_loss' was not in top 1\n",
      "Epoch 139, global step 14000: 'train_loss' was not in top 1\n",
      "Epoch 140, global step 14100: 'train_loss' was not in top 1\n",
      "Epoch 141, global step 14200: 'train_loss' was not in top 1\n",
      "Epoch 142, global step 14300: 'train_loss' reached 14.23809 (best 14.23809), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=142-step=14300.ckpt' as top 1\n",
      "Epoch 143, global step 14400: 'train_loss' reached 10.85147 (best 10.85147), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=143-step=14400.ckpt' as top 1\n",
      "Epoch 144, global step 14500: 'train_loss' was not in top 1\n",
      "Epoch 145, global step 14600: 'train_loss' reached 10.34648 (best 10.34648), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=145-step=14600.ckpt' as top 1\n",
      "Epoch 146, global step 14700: 'train_loss' reached 9.69981 (best 9.69981), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=146-step=14700.ckpt' as top 1\n",
      "Epoch 147, global step 14800: 'train_loss' was not in top 1\n",
      "Epoch 148, global step 14900: 'train_loss' was not in top 1\n",
      "Epoch 149, global step 15000: 'train_loss' reached 8.87825 (best 8.87825), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=149-step=15000.ckpt' as top 1\n",
      "Epoch 150, global step 15100: 'train_loss' was not in top 1\n",
      "Epoch 151, global step 15200: 'train_loss' was not in top 1\n",
      "Epoch 152, global step 15300: 'train_loss' was not in top 1\n",
      "Epoch 153, global step 15400: 'train_loss' was not in top 1\n",
      "Epoch 154, global step 15500: 'train_loss' was not in top 1\n",
      "Epoch 155, global step 15600: 'train_loss' reached 8.44367 (best 8.44367), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=155-step=15600.ckpt' as top 1\n",
      "Epoch 156, global step 15700: 'train_loss' was not in top 1\n",
      "Epoch 157, global step 15800: 'train_loss' was not in top 1\n",
      "Epoch 158, global step 15900: 'train_loss' was not in top 1\n",
      "Epoch 159, global step 16000: 'train_loss' was not in top 1\n",
      "Epoch 160, global step 16100: 'train_loss' was not in top 1\n",
      "Epoch 161, global step 16200: 'train_loss' was not in top 1\n",
      "Epoch 162, global step 16300: 'train_loss' was not in top 1\n",
      "Epoch 163, global step 16400: 'train_loss' was not in top 1\n",
      "Epoch 164, global step 16500: 'train_loss' was not in top 1\n",
      "Epoch 165, global step 16600: 'train_loss' was not in top 1\n",
      "Epoch 166, global step 16700: 'train_loss' reached 8.06221 (best 8.06221), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=166-step=16700.ckpt' as top 1\n",
      "Epoch 167, global step 16800: 'train_loss' was not in top 1\n",
      "Epoch 168, global step 16900: 'train_loss' was not in top 1\n",
      "Epoch 169, global step 17000: 'train_loss' was not in top 1\n",
      "Epoch 170, global step 17100: 'train_loss' was not in top 1\n",
      "Epoch 171, global step 17200: 'train_loss' was not in top 1\n",
      "Epoch 172, global step 17300: 'train_loss' was not in top 1\n",
      "Epoch 173, global step 17400: 'train_loss' was not in top 1\n",
      "Epoch 174, global step 17500: 'train_loss' was not in top 1\n",
      "Epoch 175, global step 17600: 'train_loss' was not in top 1\n",
      "Epoch 176, global step 17700: 'train_loss' was not in top 1\n",
      "Epoch 177, global step 17800: 'train_loss' was not in top 1\n",
      "Epoch 178, global step 17900: 'train_loss' reached 6.95330 (best 6.95330), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=178-step=17900.ckpt' as top 1\n",
      "Epoch 179, global step 18000: 'train_loss' reached 5.49729 (best 5.49729), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=179-step=18000.ckpt' as top 1\n",
      "Epoch 180, global step 18100: 'train_loss' was not in top 1\n",
      "Epoch 181, global step 18200: 'train_loss' reached 4.95007 (best 4.95007), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=181-step=18200.ckpt' as top 1\n",
      "Epoch 182, global step 18300: 'train_loss' reached 4.67047 (best 4.67047), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=182-step=18300.ckpt' as top 1\n",
      "Epoch 183, global step 18400: 'train_loss' was not in top 1\n",
      "Epoch 184, global step 18500: 'train_loss' was not in top 1\n",
      "Epoch 185, global step 18600: 'train_loss' was not in top 1\n",
      "Epoch 186, global step 18700: 'train_loss' was not in top 1\n",
      "Epoch 187, global step 18800: 'train_loss' was not in top 1\n",
      "Epoch 188, global step 18900: 'train_loss' was not in top 1\n",
      "Epoch 189, global step 19000: 'train_loss' reached 4.61405 (best 4.61405), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=189-step=19000.ckpt' as top 1\n",
      "Epoch 190, global step 19100: 'train_loss' was not in top 1\n",
      "Epoch 191, global step 19200: 'train_loss' was not in top 1\n",
      "Epoch 192, global step 19300: 'train_loss' was not in top 1\n",
      "Epoch 193, global step 19400: 'train_loss' was not in top 1\n",
      "Epoch 194, global step 19500: 'train_loss' was not in top 1\n",
      "Epoch 195, global step 19600: 'train_loss' was not in top 1\n",
      "Epoch 196, global step 19700: 'train_loss' was not in top 1\n",
      "Epoch 197, global step 19800: 'train_loss' was not in top 1\n",
      "Epoch 198, global step 19900: 'train_loss' was not in top 1\n",
      "Epoch 199, global step 20000: 'train_loss' was not in top 1\n",
      "Epoch 200, global step 20100: 'train_loss' was not in top 1\n",
      "Epoch 201, global step 20200: 'train_loss' reached 3.84814 (best 3.84814), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=201-step=20200.ckpt' as top 1\n",
      "Epoch 202, global step 20300: 'train_loss' reached 3.16597 (best 3.16597), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=202-step=20300.ckpt' as top 1\n",
      "Epoch 203, global step 20400: 'train_loss' was not in top 1\n",
      "Epoch 204, global step 20500: 'train_loss' was not in top 1\n",
      "Epoch 205, global step 20600: 'train_loss' was not in top 1\n",
      "Epoch 206, global step 20700: 'train_loss' was not in top 1\n",
      "Epoch 207, global step 20800: 'train_loss' was not in top 1\n",
      "Epoch 208, global step 20900: 'train_loss' was not in top 1\n",
      "Epoch 209, global step 21000: 'train_loss' was not in top 1\n",
      "Epoch 210, global step 21100: 'train_loss' was not in top 1\n",
      "Epoch 211, global step 21200: 'train_loss' was not in top 1\n",
      "Epoch 212, global step 21300: 'train_loss' was not in top 1\n",
      "Epoch 213, global step 21400: 'train_loss' was not in top 1\n",
      "Epoch 214, global step 21500: 'train_loss' was not in top 1\n",
      "Epoch 215, global step 21600: 'train_loss' was not in top 1\n",
      "Epoch 216, global step 21700: 'train_loss' was not in top 1\n",
      "Epoch 217, global step 21800: 'train_loss' reached 2.58617 (best 2.58617), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=217-step=21800.ckpt' as top 1\n",
      "Epoch 218, global step 21900: 'train_loss' was not in top 1\n",
      "Epoch 219, global step 22000: 'train_loss' was not in top 1\n",
      "Epoch 220, global step 22100: 'train_loss' reached 1.93957 (best 1.93957), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=220-step=22100.ckpt' as top 1\n",
      "Epoch 221, global step 22200: 'train_loss' was not in top 1\n",
      "Epoch 222, global step 22300: 'train_loss' was not in top 1\n",
      "Epoch 223, global step 22400: 'train_loss' reached 1.92905 (best 1.92905), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=223-step=22400.ckpt' as top 1\n",
      "Epoch 224, global step 22500: 'train_loss' was not in top 1\n",
      "Epoch 225, global step 22600: 'train_loss' was not in top 1\n",
      "Epoch 226, global step 22700: 'train_loss' was not in top 1\n",
      "Epoch 227, global step 22800: 'train_loss' was not in top 1\n",
      "Epoch 228, global step 22900: 'train_loss' was not in top 1\n",
      "Epoch 229, global step 23000: 'train_loss' was not in top 1\n",
      "Epoch 230, global step 23100: 'train_loss' was not in top 1\n",
      "Epoch 231, global step 23200: 'train_loss' was not in top 1\n",
      "Epoch 232, global step 23300: 'train_loss' was not in top 1\n",
      "Epoch 233, global step 23400: 'train_loss' was not in top 1\n",
      "Epoch 234, global step 23500: 'train_loss' was not in top 1\n",
      "Epoch 235, global step 23600: 'train_loss' was not in top 1\n",
      "Epoch 236, global step 23700: 'train_loss' reached 1.92155 (best 1.92155), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=236-step=23700.ckpt' as top 1\n",
      "Epoch 237, global step 23800: 'train_loss' was not in top 1\n",
      "Epoch 238, global step 23900: 'train_loss' was not in top 1\n",
      "Epoch 239, global step 24000: 'train_loss' was not in top 1\n",
      "Epoch 240, global step 24100: 'train_loss' was not in top 1\n",
      "Epoch 241, global step 24200: 'train_loss' was not in top 1\n",
      "Epoch 242, global step 24300: 'train_loss' was not in top 1\n",
      "Epoch 243, global step 24400: 'train_loss' reached 1.80206 (best 1.80206), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=243-step=24400.ckpt' as top 1\n",
      "Epoch 244, global step 24500: 'train_loss' was not in top 1\n",
      "Epoch 245, global step 24600: 'train_loss' was not in top 1\n",
      "Epoch 246, global step 24700: 'train_loss' was not in top 1\n",
      "Epoch 247, global step 24800: 'train_loss' was not in top 1\n",
      "Epoch 248, global step 24900: 'train_loss' reached 1.54410 (best 1.54410), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=248-step=24900.ckpt' as top 1\n",
      "Epoch 249, global step 25000: 'train_loss' was not in top 1\n",
      "Epoch 250, global step 25100: 'train_loss' was not in top 1\n",
      "Epoch 251, global step 25200: 'train_loss' was not in top 1\n",
      "Epoch 252, global step 25300: 'train_loss' was not in top 1\n",
      "Epoch 253, global step 25400: 'train_loss' was not in top 1\n",
      "Epoch 254, global step 25500: 'train_loss' was not in top 1\n",
      "Epoch 255, global step 25600: 'train_loss' was not in top 1\n",
      "Epoch 256, global step 25700: 'train_loss' was not in top 1\n",
      "Epoch 257, global step 25800: 'train_loss' was not in top 1\n",
      "Epoch 258, global step 25900: 'train_loss' was not in top 1\n",
      "Epoch 259, global step 26000: 'train_loss' was not in top 1\n",
      "Epoch 260, global step 26100: 'train_loss' was not in top 1\n",
      "Epoch 261, global step 26200: 'train_loss' was not in top 1\n",
      "Epoch 262, global step 26300: 'train_loss' was not in top 1\n",
      "Epoch 263, global step 26400: 'train_loss' was not in top 1\n",
      "Epoch 264, global step 26500: 'train_loss' was not in top 1\n",
      "Epoch 265, global step 26600: 'train_loss' was not in top 1\n",
      "Epoch 266, global step 26700: 'train_loss' was not in top 1\n",
      "Epoch 267, global step 26800: 'train_loss' was not in top 1\n",
      "Epoch 268, global step 26900: 'train_loss' was not in top 1\n",
      "Epoch 269, global step 27000: 'train_loss' was not in top 1\n",
      "Epoch 270, global step 27100: 'train_loss' was not in top 1\n",
      "Epoch 271, global step 27200: 'train_loss' was not in top 1\n",
      "Epoch 272, global step 27300: 'train_loss' was not in top 1\n",
      "Epoch 273, global step 27400: 'train_loss' was not in top 1\n",
      "Epoch 274, global step 27500: 'train_loss' was not in top 1\n",
      "Epoch 275, global step 27600: 'train_loss' was not in top 1\n",
      "Epoch 276, global step 27700: 'train_loss' was not in top 1\n",
      "Epoch 277, global step 27800: 'train_loss' was not in top 1\n",
      "Epoch 278, global step 27900: 'train_loss' was not in top 1\n",
      "Epoch 279, global step 28000: 'train_loss' reached 1.35636 (best 1.35636), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=279-step=28000.ckpt' as top 1\n",
      "Epoch 280, global step 28100: 'train_loss' was not in top 1\n",
      "Epoch 281, global step 28200: 'train_loss' was not in top 1\n",
      "Epoch 282, global step 28300: 'train_loss' was not in top 1\n",
      "Epoch 283, global step 28400: 'train_loss' was not in top 1\n",
      "Epoch 284, global step 28500: 'train_loss' was not in top 1\n",
      "Epoch 285, global step 28600: 'train_loss' was not in top 1\n",
      "Epoch 286, global step 28700: 'train_loss' was not in top 1\n",
      "Epoch 287, global step 28800: 'train_loss' was not in top 1\n",
      "Epoch 288, global step 28900: 'train_loss' was not in top 1\n",
      "Epoch 289, global step 29000: 'train_loss' was not in top 1\n",
      "Epoch 290, global step 29100: 'train_loss' reached 1.21559 (best 1.21559), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=290-step=29100.ckpt' as top 1\n",
      "Epoch 291, global step 29200: 'train_loss' was not in top 1\n",
      "Epoch 292, global step 29300: 'train_loss' was not in top 1\n",
      "Epoch 293, global step 29400: 'train_loss' was not in top 1\n",
      "Epoch 294, global step 29500: 'train_loss' was not in top 1\n",
      "Epoch 295, global step 29600: 'train_loss' was not in top 1\n",
      "Epoch 296, global step 29700: 'train_loss' was not in top 1\n",
      "Epoch 297, global step 29800: 'train_loss' was not in top 1\n",
      "Epoch 298, global step 29900: 'train_loss' was not in top 1\n",
      "Epoch 299, global step 30000: 'train_loss' was not in top 1\n",
      "Epoch 300, global step 30100: 'train_loss' was not in top 1\n",
      "Epoch 301, global step 30200: 'train_loss' was not in top 1\n",
      "Epoch 302, global step 30300: 'train_loss' was not in top 1\n",
      "Epoch 303, global step 30400: 'train_loss' was not in top 1\n",
      "Epoch 304, global step 30500: 'train_loss' was not in top 1\n",
      "Epoch 305, global step 30600: 'train_loss' was not in top 1\n",
      "Epoch 306, global step 30700: 'train_loss' was not in top 1\n",
      "Epoch 307, global step 30800: 'train_loss' was not in top 1\n",
      "Epoch 308, global step 30900: 'train_loss' was not in top 1\n",
      "Epoch 309, global step 31000: 'train_loss' was not in top 1\n",
      "Epoch 310, global step 31100: 'train_loss' was not in top 1\n",
      "Epoch 311, global step 31200: 'train_loss' was not in top 1\n",
      "Epoch 312, global step 31300: 'train_loss' was not in top 1\n",
      "Epoch 313, global step 31400: 'train_loss' was not in top 1\n",
      "Epoch 314, global step 31500: 'train_loss' was not in top 1\n",
      "Epoch 315, global step 31600: 'train_loss' was not in top 1\n",
      "Epoch 316, global step 31700: 'train_loss' was not in top 1\n",
      "Epoch 317, global step 31800: 'train_loss' was not in top 1\n",
      "Epoch 318, global step 31900: 'train_loss' reached 1.12677 (best 1.12677), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=318-step=31900.ckpt' as top 1\n",
      "Epoch 319, global step 32000: 'train_loss' was not in top 1\n",
      "Epoch 320, global step 32100: 'train_loss' was not in top 1\n",
      "Epoch 321, global step 32200: 'train_loss' was not in top 1\n",
      "Epoch 322, global step 32300: 'train_loss' was not in top 1\n",
      "Epoch 323, global step 32400: 'train_loss' was not in top 1\n",
      "Epoch 324, global step 32500: 'train_loss' was not in top 1\n",
      "Epoch 325, global step 32600: 'train_loss' was not in top 1\n",
      "Epoch 326, global step 32700: 'train_loss' was not in top 1\n",
      "Epoch 327, global step 32800: 'train_loss' was not in top 1\n",
      "Epoch 328, global step 32900: 'train_loss' was not in top 1\n",
      "Epoch 329, global step 33000: 'train_loss' was not in top 1\n",
      "Epoch 330, global step 33100: 'train_loss' was not in top 1\n",
      "Epoch 331, global step 33200: 'train_loss' was not in top 1\n",
      "Epoch 332, global step 33300: 'train_loss' was not in top 1\n",
      "Epoch 333, global step 33400: 'train_loss' was not in top 1\n",
      "Epoch 334, global step 33500: 'train_loss' was not in top 1\n",
      "Epoch 335, global step 33600: 'train_loss' was not in top 1\n",
      "Epoch 336, global step 33700: 'train_loss' was not in top 1\n",
      "Epoch 337, global step 33800: 'train_loss' was not in top 1\n",
      "Epoch 338, global step 33900: 'train_loss' was not in top 1\n",
      "Epoch 339, global step 34000: 'train_loss' was not in top 1\n",
      "Epoch 340, global step 34100: 'train_loss' was not in top 1\n",
      "Epoch 341, global step 34200: 'train_loss' was not in top 1\n",
      "Epoch 342, global step 34300: 'train_loss' was not in top 1\n",
      "Epoch 343, global step 34400: 'train_loss' was not in top 1\n",
      "Epoch 344, global step 34500: 'train_loss' was not in top 1\n",
      "Epoch 345, global step 34600: 'train_loss' was not in top 1\n",
      "Epoch 346, global step 34700: 'train_loss' was not in top 1\n",
      "Epoch 347, global step 34800: 'train_loss' reached 1.01065 (best 1.01065), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=347-step=34800.ckpt' as top 1\n",
      "Epoch 348, global step 34900: 'train_loss' was not in top 1\n",
      "Epoch 349, global step 35000: 'train_loss' was not in top 1\n",
      "Epoch 350, global step 35100: 'train_loss' was not in top 1\n",
      "Epoch 351, global step 35200: 'train_loss' was not in top 1\n",
      "Epoch 352, global step 35300: 'train_loss' was not in top 1\n",
      "Epoch 353, global step 35400: 'train_loss' was not in top 1\n",
      "Epoch 354, global step 35500: 'train_loss' was not in top 1\n",
      "Epoch 355, global step 35600: 'train_loss' was not in top 1\n",
      "Epoch 356, global step 35700: 'train_loss' was not in top 1\n",
      "Epoch 357, global step 35800: 'train_loss' was not in top 1\n",
      "Epoch 358, global step 35900: 'train_loss' was not in top 1\n",
      "Epoch 359, global step 36000: 'train_loss' was not in top 1\n",
      "Epoch 360, global step 36100: 'train_loss' was not in top 1\n",
      "Epoch 361, global step 36200: 'train_loss' was not in top 1\n",
      "Epoch 362, global step 36300: 'train_loss' was not in top 1\n",
      "Epoch 363, global step 36400: 'train_loss' was not in top 1\n",
      "Epoch 364, global step 36500: 'train_loss' was not in top 1\n",
      "Epoch 365, global step 36600: 'train_loss' was not in top 1\n",
      "Epoch 366, global step 36700: 'train_loss' was not in top 1\n",
      "Epoch 367, global step 36800: 'train_loss' was not in top 1\n",
      "Epoch 368, global step 36900: 'train_loss' was not in top 1\n",
      "Epoch 369, global step 37000: 'train_loss' was not in top 1\n",
      "Epoch 370, global step 37100: 'train_loss' was not in top 1\n",
      "Epoch 371, global step 37200: 'train_loss' was not in top 1\n",
      "Epoch 372, global step 37300: 'train_loss' was not in top 1\n",
      "Epoch 373, global step 37400: 'train_loss' was not in top 1\n",
      "Epoch 374, global step 37500: 'train_loss' was not in top 1\n",
      "Epoch 375, global step 37600: 'train_loss' was not in top 1\n",
      "Epoch 376, global step 37700: 'train_loss' was not in top 1\n",
      "Epoch 377, global step 37800: 'train_loss' was not in top 1\n",
      "Epoch 378, global step 37900: 'train_loss' was not in top 1\n",
      "Epoch 379, global step 38000: 'train_loss' was not in top 1\n",
      "Epoch 380, global step 38100: 'train_loss' was not in top 1\n",
      "Epoch 381, global step 38200: 'train_loss' was not in top 1\n",
      "Epoch 382, global step 38300: 'train_loss' was not in top 1\n",
      "Epoch 383, global step 38400: 'train_loss' was not in top 1\n",
      "Epoch 384, global step 38500: 'train_loss' was not in top 1\n",
      "Epoch 385, global step 38600: 'train_loss' was not in top 1\n",
      "Epoch 386, global step 38700: 'train_loss' was not in top 1\n",
      "Epoch 387, global step 38800: 'train_loss' was not in top 1\n",
      "Epoch 388, global step 38900: 'train_loss' was not in top 1\n",
      "Epoch 389, global step 39000: 'train_loss' was not in top 1\n",
      "Epoch 390, global step 39100: 'train_loss' was not in top 1\n",
      "Epoch 391, global step 39200: 'train_loss' was not in top 1\n",
      "Epoch 392, global step 39300: 'train_loss' was not in top 1\n",
      "Epoch 393, global step 39400: 'train_loss' was not in top 1\n",
      "Epoch 394, global step 39500: 'train_loss' was not in top 1\n",
      "Epoch 395, global step 39600: 'train_loss' was not in top 1\n",
      "Epoch 396, global step 39700: 'train_loss' reached 0.86671 (best 0.86671), saving model to 'C:\\\\Users\\\\Windows\\\\Desktop\\\\GZS\\\\trading\\\\btc\\\\dudley\\\\lightning_logs\\\\version_78\\\\checkpoints\\\\epoch=396-step=39700.ckpt' as top 1\n",
      "Epoch 397, global step 39800: 'train_loss' was not in top 1\n",
      "Epoch 398, global step 39900: 'train_loss' was not in top 1\n",
      "Epoch 399, global step 40000: 'train_loss' was not in top 1\n",
      "Epoch 400, global step 40100: 'train_loss' was not in top 1\n",
      "Epoch 401, global step 40200: 'train_loss' was not in top 1\n",
      "Epoch 402, global step 40300: 'train_loss' was not in top 1\n",
      "Epoch 403, global step 40400: 'train_loss' was not in top 1\n",
      "Epoch 404, global step 40500: 'train_loss' was not in top 1\n",
      "Epoch 405, global step 40600: 'train_loss' was not in top 1\n",
      "Epoch 406, global step 40700: 'train_loss' was not in top 1\n",
      "Epoch 407, global step 40800: 'train_loss' was not in top 1\n",
      "Epoch 408, global step 40900: 'train_loss' was not in top 1\n",
      "Epoch 409, global step 41000: 'train_loss' was not in top 1\n",
      "Epoch 410, global step 41100: 'train_loss' was not in top 1\n",
      "Epoch 411, global step 41200: 'train_loss' was not in top 1\n",
      "Epoch 412, global step 41300: 'train_loss' was not in top 1\n",
      "Epoch 413, global step 41400: 'train_loss' was not in top 1\n",
      "Epoch 414, global step 41500: 'train_loss' was not in top 1\n",
      "Epoch 415, global step 41600: 'train_loss' was not in top 1\n",
      "Epoch 416, global step 41700: 'train_loss' was not in top 1\n",
      "Epoch 417, global step 41800: 'train_loss' was not in top 1\n",
      "Epoch 418, global step 41900: 'train_loss' was not in top 1\n",
      "Epoch 419, global step 42000: 'train_loss' was not in top 1\n",
      "Epoch 420, global step 42100: 'train_loss' was not in top 1\n",
      "Epoch 421, global step 42200: 'train_loss' was not in top 1\n",
      "Epoch 422, global step 42300: 'train_loss' was not in top 1\n",
      "Epoch 423, global step 42400: 'train_loss' was not in top 1\n",
      "Epoch 424, global step 42500: 'train_loss' was not in top 1\n",
      "Epoch 425, global step 42600: 'train_loss' was not in top 1\n",
      "Epoch 426, global step 42700: 'train_loss' was not in top 1\n",
      "Epoch 427, global step 42800: 'train_loss' was not in top 1\n",
      "Epoch 428, global step 42900: 'train_loss' was not in top 1\n",
      "Epoch 429, global step 43000: 'train_loss' was not in top 1\n",
      "Epoch 430, global step 43100: 'train_loss' was not in top 1\n",
      "Epoch 431, global step 43200: 'train_loss' was not in top 1\n",
      "Epoch 432, global step 43300: 'train_loss' was not in top 1\n",
      "Epoch 433, global step 43400: 'train_loss' was not in top 1\n",
      "Epoch 434, global step 43500: 'train_loss' was not in top 1\n",
      "Epoch 435, global step 43600: 'train_loss' was not in top 1\n",
      "Epoch 436, global step 43700: 'train_loss' was not in top 1\n",
      "Epoch 437, global step 43800: 'train_loss' was not in top 1\n",
      "Epoch 438, global step 43900: 'train_loss' was not in top 1\n",
      "Epoch 439, global step 44000: 'train_loss' was not in top 1\n",
      "Epoch 440, global step 44100: 'train_loss' was not in top 1\n",
      "Epoch 441, global step 44200: 'train_loss' was not in top 1\n",
      "Epoch 442, global step 44300: 'train_loss' was not in top 1\n",
      "Epoch 443, global step 44400: 'train_loss' was not in top 1\n",
      "Epoch 444, global step 44500: 'train_loss' was not in top 1\n",
      "Epoch 445, global step 44600: 'train_loss' was not in top 1\n",
      "Epoch 446, global step 44700: 'train_loss' was not in top 1\n",
      "Epoch 447, global step 44800: 'train_loss' was not in top 1\n",
      "Epoch 448, global step 44900: 'train_loss' was not in top 1\n",
      "Epoch 449, global step 45000: 'train_loss' was not in top 1\n",
      "Epoch 450, global step 45100: 'train_loss' was not in top 1\n",
      "Epoch 451, global step 45200: 'train_loss' was not in top 1\n",
      "Epoch 452, global step 45300: 'train_loss' was not in top 1\n",
      "Epoch 453, global step 45400: 'train_loss' was not in top 1\n",
      "Epoch 454, global step 45500: 'train_loss' was not in top 1\n",
      "Epoch 455, global step 45600: 'train_loss' was not in top 1\n",
      "Epoch 456, global step 45700: 'train_loss' was not in top 1\n",
      "Epoch 457, global step 45800: 'train_loss' was not in top 1\n",
      "Epoch 458, global step 45900: 'train_loss' was not in top 1\n",
      "Epoch 459, global step 46000: 'train_loss' was not in top 1\n",
      "Epoch 460, global step 46100: 'train_loss' was not in top 1\n",
      "Epoch 461, global step 46200: 'train_loss' was not in top 1\n",
      "Epoch 462, global step 46300: 'train_loss' was not in top 1\n",
      "Epoch 463, global step 46400: 'train_loss' was not in top 1\n",
      "Epoch 464, global step 46500: 'train_loss' was not in top 1\n",
      "Epoch 465, global step 46600: 'train_loss' was not in top 1\n",
      "Epoch 466, global step 46700: 'train_loss' was not in top 1\n",
      "Epoch 467, global step 46800: 'train_loss' was not in top 1\n",
      "Epoch 468, global step 46900: 'train_loss' was not in top 1\n",
      "Epoch 469, global step 47000: 'train_loss' was not in top 1\n",
      "Epoch 470, global step 47100: 'train_loss' was not in top 1\n",
      "Epoch 471, global step 47200: 'train_loss' was not in top 1\n",
      "Epoch 472, global step 47300: 'train_loss' was not in top 1\n",
      "Epoch 473, global step 47400: 'train_loss' was not in top 1\n",
      "Epoch 474, global step 47500: 'train_loss' was not in top 1\n",
      "Epoch 475, global step 47600: 'train_loss' was not in top 1\n",
      "Epoch 476, global step 47700: 'train_loss' was not in top 1\n",
      "Epoch 477, global step 47800: 'train_loss' was not in top 1\n",
      "Epoch 478, global step 47900: 'train_loss' was not in top 1\n",
      "Epoch 479, global step 48000: 'train_loss' was not in top 1\n",
      "Epoch 480, global step 48100: 'train_loss' was not in top 1\n",
      "Epoch 481, global step 48200: 'train_loss' was not in top 1\n",
      "Epoch 482, global step 48300: 'train_loss' was not in top 1\n",
      "Epoch 483, global step 48400: 'train_loss' was not in top 1\n",
      "Epoch 484, global step 48500: 'train_loss' was not in top 1\n",
      "Epoch 485, global step 48600: 'train_loss' was not in top 1\n",
      "Epoch 486, global step 48700: 'train_loss' was not in top 1\n",
      "Epoch 487, global step 48800: 'train_loss' was not in top 1\n",
      "Epoch 488, global step 48900: 'train_loss' was not in top 1\n",
      "Epoch 489, global step 49000: 'train_loss' was not in top 1\n",
      "Epoch 490, global step 49100: 'train_loss' was not in top 1\n",
      "Epoch 491, global step 49200: 'train_loss' was not in top 1\n",
      "Epoch 492, global step 49300: 'train_loss' was not in top 1\n",
      "Epoch 493, global step 49400: 'train_loss' was not in top 1\n",
      "Epoch 494, global step 49500: 'train_loss' was not in top 1\n",
      "Epoch 495, global step 49600: 'train_loss' was not in top 1\n",
      "Epoch 496, global step 49700: 'train_loss' was not in top 1\n",
      "Epoch 497, global step 49800: 'train_loss' was not in top 1\n",
      "Epoch 498, global step 49900: 'train_loss' was not in top 1\n",
      "Epoch 499, global step 50000: 'train_loss' was not in top 1\n",
      "Epoch 500, global step 50100: 'train_loss' was not in top 1\n",
      "Epoch 501, global step 50200: 'train_loss' was not in top 1\n",
      "Epoch 502, global step 50300: 'train_loss' was not in top 1\n",
      "Epoch 503, global step 50400: 'train_loss' was not in top 1\n",
      "Epoch 504, global step 50500: 'train_loss' was not in top 1\n",
      "Epoch 505, global step 50600: 'train_loss' was not in top 1\n",
      "Epoch 506, global step 50700: 'train_loss' was not in top 1\n",
      "Epoch 507, global step 50800: 'train_loss' was not in top 1\n",
      "Epoch 508, global step 50900: 'train_loss' was not in top 1\n",
      "Epoch 509, global step 51000: 'train_loss' was not in top 1\n",
      "Epoch 510, global step 51100: 'train_loss' was not in top 1\n",
      "Epoch 511, global step 51200: 'train_loss' was not in top 1\n",
      "Epoch 512, global step 51300: 'train_loss' was not in top 1\n",
      "Epoch 513, global step 51400: 'train_loss' was not in top 1\n",
      "Epoch 514, global step 51500: 'train_loss' was not in top 1\n",
      "Epoch 515, global step 51600: 'train_loss' was not in top 1\n",
      "Epoch 516, global step 51700: 'train_loss' was not in top 1\n",
      "Epoch 517, global step 51800: 'train_loss' was not in top 1\n",
      "Epoch 518, global step 51900: 'train_loss' was not in top 1\n",
      "Epoch 519, global step 52000: 'train_loss' was not in top 1\n",
      "Epoch 520, global step 52100: 'train_loss' was not in top 1\n",
      "Epoch 521, global step 52200: 'train_loss' was not in top 1\n",
      "Epoch 522, global step 52300: 'train_loss' was not in top 1\n",
      "Epoch 523, global step 52400: 'train_loss' was not in top 1\n",
      "Epoch 524, global step 52500: 'train_loss' was not in top 1\n",
      "Epoch 525, global step 52600: 'train_loss' was not in top 1\n",
      "Epoch 526, global step 52700: 'train_loss' was not in top 1\n",
      "Epoch 527, global step 52800: 'train_loss' was not in top 1\n",
      "Epoch 528, global step 52900: 'train_loss' was not in top 1\n",
      "Epoch 529, global step 53000: 'train_loss' was not in top 1\n",
      "Epoch 530, global step 53100: 'train_loss' was not in top 1\n",
      "Epoch 531, global step 53200: 'train_loss' was not in top 1\n",
      "Epoch 532, global step 53300: 'train_loss' was not in top 1\n",
      "Epoch 533, global step 53400: 'train_loss' was not in top 1\n",
      "Epoch 534, global step 53500: 'train_loss' was not in top 1\n",
      "Epoch 535, global step 53600: 'train_loss' was not in top 1\n",
      "Epoch 536, global step 53700: 'train_loss' was not in top 1\n",
      "Epoch 537, global step 53800: 'train_loss' was not in top 1\n",
      "Epoch 538, global step 53900: 'train_loss' was not in top 1\n",
      "Epoch 539, global step 54000: 'train_loss' was not in top 1\n",
      "Epoch 540, global step 54100: 'train_loss' was not in top 1\n",
      "Epoch 541, global step 54200: 'train_loss' was not in top 1\n",
      "Epoch 542, global step 54300: 'train_loss' was not in top 1\n",
      "Epoch 543, global step 54400: 'train_loss' was not in top 1\n",
      "Epoch 544, global step 54500: 'train_loss' was not in top 1\n",
      "Epoch 545, global step 54600: 'train_loss' was not in top 1\n",
      "Epoch 546, global step 54700: 'train_loss' was not in top 1\n",
      "Epoch 547, global step 54800: 'train_loss' was not in top 1\n",
      "Epoch 548, global step 54900: 'train_loss' was not in top 1\n",
      "Epoch 549, global step 55000: 'train_loss' was not in top 1\n",
      "Epoch 550, global step 55100: 'train_loss' was not in top 1\n",
      "Epoch 551, global step 55200: 'train_loss' was not in top 1\n",
      "Epoch 552, global step 55300: 'train_loss' was not in top 1\n",
      "Epoch 553, global step 55400: 'train_loss' was not in top 1\n",
      "Epoch 554, global step 55500: 'train_loss' was not in top 1\n",
      "Epoch 555, global step 55600: 'train_loss' was not in top 1\n",
      "Epoch 556, global step 55700: 'train_loss' was not in top 1\n",
      "Epoch 557, global step 55800: 'train_loss' was not in top 1\n",
      "Epoch 558, global step 55900: 'train_loss' was not in top 1\n",
      "Epoch 559, global step 56000: 'train_loss' was not in top 1\n",
      "Epoch 560, global step 56100: 'train_loss' was not in top 1\n",
      "Epoch 561, global step 56200: 'train_loss' was not in top 1\n",
      "Epoch 562, global step 56300: 'train_loss' was not in top 1\n",
      "Epoch 563, global step 56400: 'train_loss' was not in top 1\n",
      "Epoch 564, global step 56500: 'train_loss' was not in top 1\n",
      "Epoch 565, global step 56600: 'train_loss' was not in top 1\n",
      "Epoch 566, global step 56700: 'train_loss' was not in top 1\n",
      "Epoch 567, global step 56800: 'train_loss' was not in top 1\n",
      "Epoch 568, global step 56900: 'train_loss' was not in top 1\n",
      "Epoch 569, global step 57000: 'train_loss' was not in top 1\n",
      "Epoch 570, global step 57100: 'train_loss' was not in top 1\n",
      "Epoch 571, global step 57200: 'train_loss' was not in top 1\n",
      "Epoch 572, global step 57300: 'train_loss' was not in top 1\n",
      "Epoch 573, global step 57400: 'train_loss' was not in top 1\n",
      "Epoch 574, global step 57500: 'train_loss' was not in top 1\n",
      "Epoch 575, global step 57600: 'train_loss' was not in top 1\n",
      "Epoch 576, global step 57700: 'train_loss' was not in top 1\n",
      "Epoch 577, global step 57800: 'train_loss' was not in top 1\n",
      "Epoch 578, global step 57900: 'train_loss' was not in top 1\n",
      "Epoch 579, global step 58000: 'train_loss' was not in top 1\n",
      "Epoch 580, global step 58100: 'train_loss' was not in top 1\n",
      "Epoch 581, global step 58200: 'train_loss' was not in top 1\n",
      "Epoch 582, global step 58300: 'train_loss' was not in top 1\n",
      "Epoch 583, global step 58400: 'train_loss' was not in top 1\n",
      "Epoch 584, global step 58500: 'train_loss' was not in top 1\n",
      "Epoch 585, global step 58600: 'train_loss' was not in top 1\n",
      "Epoch 586, global step 58700: 'train_loss' was not in top 1\n",
      "Epoch 587, global step 58800: 'train_loss' was not in top 1\n",
      "Epoch 588, global step 58900: 'train_loss' was not in top 1\n",
      "Epoch 589, global step 59000: 'train_loss' was not in top 1\n",
      "Epoch 590, global step 59100: 'train_loss' was not in top 1\n",
      "Epoch 591, global step 59200: 'train_loss' was not in top 1\n",
      "Epoch 592, global step 59300: 'train_loss' was not in top 1\n",
      "Epoch 593, global step 59400: 'train_loss' was not in top 1\n",
      "Epoch 594, global step 59500: 'train_loss' was not in top 1\n",
      "Epoch 595, global step 59600: 'train_loss' was not in top 1\n",
      "Epoch 596, global step 59700: 'train_loss' was not in top 1\n",
      "Epoch 597, global step 59800: 'train_loss' was not in top 1\n",
      "Epoch 598, global step 59900: 'train_loss' was not in top 1\n",
      "Epoch 599, global step 60000: 'train_loss' was not in top 1\n",
      "Epoch 600, global step 60100: 'train_loss' was not in top 1\n",
      "Epoch 601, global step 60200: 'train_loss' was not in top 1\n",
      "Epoch 602, global step 60300: 'train_loss' was not in top 1\n",
      "Epoch 603, global step 60400: 'train_loss' was not in top 1\n",
      "Epoch 604, global step 60500: 'train_loss' was not in top 1\n",
      "Epoch 605, global step 60600: 'train_loss' was not in top 1\n",
      "Epoch 606, global step 60700: 'train_loss' was not in top 1\n",
      "Epoch 607, global step 60800: 'train_loss' was not in top 1\n",
      "Epoch 608, global step 60900: 'train_loss' was not in top 1\n",
      "Epoch 609, global step 61000: 'train_loss' was not in top 1\n",
      "Epoch 610, global step 61100: 'train_loss' was not in top 1\n",
      "Epoch 611, global step 61200: 'train_loss' was not in top 1\n",
      "Epoch 612, global step 61300: 'train_loss' was not in top 1\n",
      "Epoch 613, global step 61400: 'train_loss' was not in top 1\n",
      "Epoch 614, global step 61500: 'train_loss' was not in top 1\n",
      "Epoch 615, global step 61600: 'train_loss' was not in top 1\n",
      "Epoch 616, global step 61700: 'train_loss' was not in top 1\n",
      "Epoch 617, global step 61800: 'train_loss' was not in top 1\n",
      "Epoch 618, global step 61900: 'train_loss' was not in top 1\n",
      "Epoch 619, global step 62000: 'train_loss' was not in top 1\n",
      "Epoch 620, global step 62100: 'train_loss' was not in top 1\n",
      "Epoch 621, global step 62200: 'train_loss' was not in top 1\n",
      "Epoch 622, global step 62300: 'train_loss' was not in top 1\n",
      "Epoch 623, global step 62400: 'train_loss' was not in top 1\n",
      "Epoch 624, global step 62500: 'train_loss' was not in top 1\n",
      "Epoch 625, global step 62600: 'train_loss' was not in top 1\n",
      "Epoch 626, global step 62700: 'train_loss' was not in top 1\n",
      "Epoch 627, global step 62800: 'train_loss' was not in top 1\n",
      "Epoch 628, global step 62900: 'train_loss' was not in top 1\n",
      "Epoch 629, global step 63000: 'train_loss' was not in top 1\n",
      "Epoch 630, global step 63100: 'train_loss' was not in top 1\n",
      "Epoch 631, global step 63200: 'train_loss' was not in top 1\n",
      "Epoch 632, global step 63300: 'train_loss' was not in top 1\n",
      "Epoch 633, global step 63400: 'train_loss' was not in top 1\n",
      "Epoch 634, global step 63500: 'train_loss' was not in top 1\n",
      "Epoch 635, global step 63600: 'train_loss' was not in top 1\n",
      "Epoch 636, global step 63700: 'train_loss' was not in top 1\n",
      "Epoch 637, global step 63800: 'train_loss' was not in top 1\n",
      "Epoch 638, global step 63900: 'train_loss' was not in top 1\n",
      "Epoch 639, global step 64000: 'train_loss' was not in top 1\n",
      "Epoch 640, global step 64100: 'train_loss' was not in top 1\n",
      "Epoch 641, global step 64200: 'train_loss' was not in top 1\n",
      "Epoch 642, global step 64300: 'train_loss' was not in top 1\n",
      "Epoch 643, global step 64400: 'train_loss' was not in top 1\n",
      "Epoch 644, global step 64500: 'train_loss' was not in top 1\n",
      "Epoch 645, global step 64600: 'train_loss' was not in top 1\n",
      "Epoch 646, global step 64700: 'train_loss' was not in top 1\n",
      "Epoch 647, global step 64800: 'train_loss' was not in top 1\n",
      "Epoch 648, global step 64900: 'train_loss' was not in top 1\n",
      "Epoch 649, global step 65000: 'train_loss' was not in top 1\n",
      "Epoch 650, global step 65100: 'train_loss' was not in top 1\n",
      "Epoch 651, global step 65200: 'train_loss' was not in top 1\n",
      "Epoch 652, global step 65300: 'train_loss' was not in top 1\n",
      "Epoch 653, global step 65400: 'train_loss' was not in top 1\n",
      "Epoch 654, global step 65500: 'train_loss' was not in top 1\n",
      "Epoch 655, global step 65600: 'train_loss' was not in top 1\n",
      "Epoch 656, global step 65700: 'train_loss' was not in top 1\n",
      "Epoch 657, global step 65800: 'train_loss' was not in top 1\n",
      "Epoch 658, global step 65900: 'train_loss' was not in top 1\n",
      "Epoch 659, global step 66000: 'train_loss' was not in top 1\n",
      "Epoch 660, global step 66100: 'train_loss' was not in top 1\n",
      "Epoch 661, global step 66200: 'train_loss' was not in top 1\n",
      "Epoch 662, global step 66300: 'train_loss' was not in top 1\n",
      "Epoch 663, global step 66400: 'train_loss' was not in top 1\n",
      "Epoch 664, global step 66500: 'train_loss' was not in top 1\n",
      "Epoch 665, global step 66600: 'train_loss' was not in top 1\n",
      "Epoch 666, global step 66700: 'train_loss' was not in top 1\n",
      "Epoch 667, global step 66800: 'train_loss' was not in top 1\n",
      "Epoch 668, global step 66900: 'train_loss' was not in top 1\n",
      "Epoch 669, global step 67000: 'train_loss' was not in top 1\n",
      "Epoch 670, global step 67100: 'train_loss' was not in top 1\n",
      "Epoch 671, global step 67200: 'train_loss' was not in top 1\n",
      "Epoch 672, global step 67300: 'train_loss' was not in top 1\n",
      "Epoch 673, global step 67400: 'train_loss' was not in top 1\n",
      "Epoch 674, global step 67500: 'train_loss' was not in top 1\n",
      "Epoch 675, global step 67600: 'train_loss' was not in top 1\n",
      "Epoch 676, global step 67700: 'train_loss' was not in top 1\n",
      "Epoch 677, global step 67800: 'train_loss' was not in top 1\n",
      "Epoch 678, global step 67900: 'train_loss' was not in top 1\n",
      "Epoch 679, global step 68000: 'train_loss' was not in top 1\n",
      "Epoch 680, global step 68100: 'train_loss' was not in top 1\n",
      "Epoch 681, global step 68200: 'train_loss' was not in top 1\n",
      "Epoch 682, global step 68300: 'train_loss' was not in top 1\n",
      "Epoch 683, global step 68400: 'train_loss' was not in top 1\n",
      "Epoch 684, global step 68500: 'train_loss' was not in top 1\n",
      "Epoch 685, global step 68600: 'train_loss' was not in top 1\n",
      "Epoch 686, global step 68700: 'train_loss' was not in top 1\n",
      "Epoch 687, global step 68800: 'train_loss' was not in top 1\n",
      "Epoch 688, global step 68900: 'train_loss' was not in top 1\n",
      "Epoch 689, global step 69000: 'train_loss' was not in top 1\n",
      "Epoch 690, global step 69100: 'train_loss' was not in top 1\n",
      "Epoch 691, global step 69200: 'train_loss' was not in top 1\n",
      "Epoch 692, global step 69300: 'train_loss' was not in top 1\n",
      "Epoch 693, global step 69400: 'train_loss' was not in top 1\n",
      "Epoch 694, global step 69500: 'train_loss' was not in top 1\n",
      "Epoch 695, global step 69600: 'train_loss' was not in top 1\n",
      "Epoch 696, global step 69700: 'train_loss' was not in top 1\n",
      "Epoch 697, global step 69800: 'train_loss' was not in top 1\n",
      "Epoch 698, global step 69900: 'train_loss' was not in top 1\n",
      "Epoch 699, global step 70000: 'train_loss' was not in top 1\n",
      "Epoch 700, global step 70100: 'train_loss' was not in top 1\n",
      "Epoch 701, global step 70200: 'train_loss' was not in top 1\n",
      "Epoch 702, global step 70300: 'train_loss' was not in top 1\n",
      "Epoch 703, global step 70400: 'train_loss' was not in top 1\n",
      "Epoch 704, global step 70500: 'train_loss' was not in top 1\n",
      "Epoch 705, global step 70600: 'train_loss' was not in top 1\n",
      "Epoch 706, global step 70700: 'train_loss' was not in top 1\n",
      "Epoch 707, global step 70800: 'train_loss' was not in top 1\n",
      "Epoch 708, global step 70900: 'train_loss' was not in top 1\n",
      "Epoch 709, global step 71000: 'train_loss' was not in top 1\n",
      "Epoch 710, global step 71100: 'train_loss' was not in top 1\n",
      "Epoch 711, global step 71200: 'train_loss' was not in top 1\n",
      "Epoch 712, global step 71300: 'train_loss' was not in top 1\n",
      "Epoch 713, global step 71400: 'train_loss' was not in top 1\n",
      "Epoch 714, global step 71500: 'train_loss' was not in top 1\n",
      "Epoch 715, global step 71600: 'train_loss' was not in top 1\n",
      "Epoch 716, global step 71700: 'train_loss' was not in top 1\n",
      "Epoch 717, global step 71800: 'train_loss' was not in top 1\n",
      "Epoch 718, global step 71900: 'train_loss' was not in top 1\n",
      "Epoch 719, global step 72000: 'train_loss' was not in top 1\n",
      "Epoch 720, global step 72100: 'train_loss' was not in top 1\n",
      "Epoch 721, global step 72200: 'train_loss' was not in top 1\n",
      "Epoch 722, global step 72300: 'train_loss' was not in top 1\n",
      "Epoch 723, global step 72400: 'train_loss' was not in top 1\n",
      "Epoch 724, global step 72500: 'train_loss' was not in top 1\n",
      "Epoch 725, global step 72600: 'train_loss' was not in top 1\n",
      "Epoch 726, global step 72700: 'train_loss' was not in top 1\n",
      "Epoch 727, global step 72800: 'train_loss' was not in top 1\n",
      "Epoch 728, global step 72900: 'train_loss' was not in top 1\n",
      "Epoch 729, global step 73000: 'train_loss' was not in top 1\n",
      "Epoch 730, global step 73100: 'train_loss' was not in top 1\n",
      "Epoch 731, global step 73200: 'train_loss' was not in top 1\n",
      "Epoch 732, global step 73300: 'train_loss' was not in top 1\n",
      "Epoch 733, global step 73400: 'train_loss' was not in top 1\n",
      "Epoch 734, global step 73500: 'train_loss' was not in top 1\n",
      "Epoch 735, global step 73600: 'train_loss' was not in top 1\n",
      "Epoch 736, global step 73700: 'train_loss' was not in top 1\n",
      "Epoch 737, global step 73800: 'train_loss' was not in top 1\n",
      "Epoch 738, global step 73900: 'train_loss' was not in top 1\n",
      "Epoch 739, global step 74000: 'train_loss' was not in top 1\n",
      "Epoch 740, global step 74100: 'train_loss' was not in top 1\n",
      "Epoch 741, global step 74200: 'train_loss' was not in top 1\n",
      "Epoch 742, global step 74300: 'train_loss' was not in top 1\n",
      "Epoch 743, global step 74400: 'train_loss' was not in top 1\n",
      "Epoch 744, global step 74500: 'train_loss' was not in top 1\n",
      "Epoch 745, global step 74600: 'train_loss' was not in top 1\n",
      "Epoch 746, global step 74700: 'train_loss' was not in top 1\n",
      "Epoch 747, global step 74800: 'train_loss' was not in top 1\n",
      "Epoch 748, global step 74900: 'train_loss' was not in top 1\n",
      "Epoch 749, global step 75000: 'train_loss' was not in top 1\n",
      "Epoch 750, global step 75100: 'train_loss' was not in top 1\n",
      "Epoch 751, global step 75200: 'train_loss' was not in top 1\n",
      "Epoch 752, global step 75300: 'train_loss' was not in top 1\n",
      "Epoch 753, global step 75400: 'train_loss' was not in top 1\n",
      "Epoch 754, global step 75500: 'train_loss' was not in top 1\n",
      "Epoch 755, global step 75600: 'train_loss' was not in top 1\n",
      "Epoch 756, global step 75700: 'train_loss' was not in top 1\n",
      "Epoch 757, global step 75800: 'train_loss' was not in top 1\n",
      "Epoch 758, global step 75900: 'train_loss' was not in top 1\n",
      "Epoch 759, global step 76000: 'train_loss' was not in top 1\n",
      "Epoch 760, global step 76100: 'train_loss' was not in top 1\n",
      "Epoch 761, global step 76200: 'train_loss' was not in top 1\n",
      "Epoch 762, global step 76300: 'train_loss' was not in top 1\n",
      "Epoch 763, global step 76400: 'train_loss' was not in top 1\n",
      "Epoch 764, global step 76500: 'train_loss' was not in top 1\n",
      "Epoch 765, global step 76600: 'train_loss' was not in top 1\n",
      "Epoch 766, global step 76700: 'train_loss' was not in top 1\n",
      "Epoch 767, global step 76800: 'train_loss' was not in top 1\n",
      "Epoch 768, global step 76900: 'train_loss' was not in top 1\n",
      "Epoch 769, global step 77000: 'train_loss' was not in top 1\n",
      "Epoch 770, global step 77100: 'train_loss' was not in top 1\n",
      "Epoch 771, global step 77200: 'train_loss' was not in top 1\n",
      "Epoch 772, global step 77300: 'train_loss' was not in top 1\n",
      "Epoch 773, global step 77400: 'train_loss' was not in top 1\n",
      "Epoch 774, global step 77500: 'train_loss' was not in top 1\n",
      "Epoch 775, global step 77600: 'train_loss' was not in top 1\n",
      "Epoch 776, global step 77700: 'train_loss' was not in top 1\n",
      "Epoch 777, global step 77800: 'train_loss' was not in top 1\n",
      "Epoch 778, global step 77900: 'train_loss' was not in top 1\n",
      "Epoch 779, global step 78000: 'train_loss' was not in top 1\n",
      "Epoch 780, global step 78100: 'train_loss' was not in top 1\n",
      "Epoch 781, global step 78200: 'train_loss' was not in top 1\n",
      "Epoch 782, global step 78300: 'train_loss' was not in top 1\n",
      "Epoch 783, global step 78400: 'train_loss' was not in top 1\n",
      "Epoch 784, global step 78500: 'train_loss' was not in top 1\n",
      "Epoch 785, global step 78600: 'train_loss' was not in top 1\n",
      "Epoch 786, global step 78700: 'train_loss' was not in top 1\n",
      "Epoch 787, global step 78800: 'train_loss' was not in top 1\n",
      "Epoch 788, global step 78900: 'train_loss' was not in top 1\n",
      "Epoch 789, global step 79000: 'train_loss' was not in top 1\n",
      "Epoch 790, global step 79100: 'train_loss' was not in top 1\n",
      "Epoch 791, global step 79200: 'train_loss' was not in top 1\n",
      "Epoch 792, global step 79300: 'train_loss' was not in top 1\n",
      "Epoch 793, global step 79400: 'train_loss' was not in top 1\n",
      "Epoch 794, global step 79500: 'train_loss' was not in top 1\n",
      "Epoch 795, global step 79600: 'train_loss' was not in top 1\n",
      "Epoch 796, global step 79700: 'train_loss' was not in top 1\n",
      "Epoch 797, global step 79800: 'train_loss' was not in top 1\n",
      "Epoch 798, global step 79900: 'train_loss' was not in top 1\n",
      "Epoch 799, global step 80000: 'train_loss' was not in top 1\n",
      "Epoch 800, global step 80100: 'train_loss' was not in top 1\n",
      "Epoch 801, global step 80200: 'train_loss' was not in top 1\n",
      "Epoch 802, global step 80300: 'train_loss' was not in top 1\n",
      "Epoch 803, global step 80400: 'train_loss' was not in top 1\n",
      "Epoch 804, global step 80500: 'train_loss' was not in top 1\n",
      "Epoch 805, global step 80600: 'train_loss' was not in top 1\n",
      "Epoch 806, global step 80700: 'train_loss' was not in top 1\n",
      "Epoch 807, global step 80800: 'train_loss' was not in top 1\n",
      "Epoch 808, global step 80900: 'train_loss' was not in top 1\n",
      "Epoch 809, global step 81000: 'train_loss' was not in top 1\n",
      "Epoch 810, global step 81100: 'train_loss' was not in top 1\n",
      "Epoch 811, global step 81200: 'train_loss' was not in top 1\n",
      "Epoch 812, global step 81300: 'train_loss' was not in top 1\n",
      "Epoch 813, global step 81400: 'train_loss' was not in top 1\n",
      "Epoch 814, global step 81500: 'train_loss' was not in top 1\n",
      "Epoch 815, global step 81600: 'train_loss' was not in top 1\n",
      "Epoch 816, global step 81700: 'train_loss' was not in top 1\n",
      "Epoch 817, global step 81800: 'train_loss' was not in top 1\n",
      "Epoch 818, global step 81900: 'train_loss' was not in top 1\n",
      "Epoch 819, global step 82000: 'train_loss' was not in top 1\n",
      "Epoch 820, global step 82100: 'train_loss' was not in top 1\n",
      "Epoch 821, global step 82200: 'train_loss' was not in top 1\n",
      "Epoch 822, global step 82300: 'train_loss' was not in top 1\n",
      "Epoch 823, global step 82400: 'train_loss' was not in top 1\n",
      "Epoch 824, global step 82500: 'train_loss' was not in top 1\n",
      "Epoch 825, global step 82600: 'train_loss' was not in top 1\n",
      "Epoch 826, global step 82700: 'train_loss' was not in top 1\n",
      "Epoch 827, global step 82800: 'train_loss' was not in top 1\n",
      "Epoch 828, global step 82900: 'train_loss' was not in top 1\n",
      "Epoch 829, global step 83000: 'train_loss' was not in top 1\n",
      "Epoch 830, global step 83100: 'train_loss' was not in top 1\n",
      "Epoch 831, global step 83200: 'train_loss' was not in top 1\n",
      "Epoch 832, global step 83300: 'train_loss' was not in top 1\n",
      "Epoch 833, global step 83400: 'train_loss' was not in top 1\n",
      "Epoch 834, global step 83500: 'train_loss' was not in top 1\n",
      "Epoch 835, global step 83600: 'train_loss' was not in top 1\n",
      "Epoch 836, global step 83700: 'train_loss' was not in top 1\n",
      "Epoch 837, global step 83800: 'train_loss' was not in top 1\n",
      "Epoch 838, global step 83900: 'train_loss' was not in top 1\n",
      "Epoch 839, global step 84000: 'train_loss' was not in top 1\n",
      "Epoch 840, global step 84100: 'train_loss' was not in top 1\n",
      "Epoch 841, global step 84200: 'train_loss' was not in top 1\n",
      "Epoch 842, global step 84300: 'train_loss' was not in top 1\n",
      "Epoch 843, global step 84400: 'train_loss' was not in top 1\n",
      "Epoch 844, global step 84500: 'train_loss' was not in top 1\n",
      "Epoch 845, global step 84600: 'train_loss' was not in top 1\n",
      "Epoch 846, global step 84700: 'train_loss' was not in top 1\n",
      "Epoch 847, global step 84800: 'train_loss' was not in top 1\n",
      "Epoch 848, global step 84900: 'train_loss' was not in top 1\n",
      "Epoch 849, global step 85000: 'train_loss' was not in top 1\n",
      "Epoch 850, global step 85100: 'train_loss' was not in top 1\n",
      "Epoch 851, global step 85200: 'train_loss' was not in top 1\n",
      "Epoch 852, global step 85300: 'train_loss' was not in top 1\n",
      "Epoch 853, global step 85400: 'train_loss' was not in top 1\n",
      "Epoch 854, global step 85500: 'train_loss' was not in top 1\n",
      "Epoch 855, global step 85600: 'train_loss' was not in top 1\n",
      "Epoch 856, global step 85700: 'train_loss' was not in top 1\n",
      "Epoch 857, global step 85800: 'train_loss' was not in top 1\n",
      "Epoch 858, global step 85900: 'train_loss' was not in top 1\n",
      "Epoch 859, global step 86000: 'train_loss' was not in top 1\n",
      "Epoch 860, global step 86100: 'train_loss' was not in top 1\n",
      "Epoch 861, global step 86200: 'train_loss' was not in top 1\n",
      "Epoch 862, global step 86300: 'train_loss' was not in top 1\n",
      "Epoch 863, global step 86400: 'train_loss' was not in top 1\n",
      "Epoch 864, global step 86500: 'train_loss' was not in top 1\n",
      "Epoch 865, global step 86600: 'train_loss' was not in top 1\n",
      "Epoch 866, global step 86700: 'train_loss' was not in top 1\n",
      "Epoch 867, global step 86800: 'train_loss' was not in top 1\n",
      "Epoch 868, global step 86900: 'train_loss' was not in top 1\n",
      "Epoch 869, global step 87000: 'train_loss' was not in top 1\n",
      "Epoch 870, global step 87100: 'train_loss' was not in top 1\n",
      "Epoch 871, global step 87200: 'train_loss' was not in top 1\n",
      "Epoch 872, global step 87300: 'train_loss' was not in top 1\n",
      "Epoch 873, global step 87400: 'train_loss' was not in top 1\n",
      "Epoch 874, global step 87500: 'train_loss' was not in top 1\n",
      "Epoch 875, global step 87600: 'train_loss' was not in top 1\n",
      "Epoch 876, global step 87700: 'train_loss' was not in top 1\n",
      "Epoch 877, global step 87800: 'train_loss' was not in top 1\n",
      "Epoch 878, global step 87900: 'train_loss' was not in top 1\n",
      "Epoch 879, global step 88000: 'train_loss' was not in top 1\n",
      "Epoch 880, global step 88100: 'train_loss' was not in top 1\n",
      "Epoch 881, global step 88200: 'train_loss' was not in top 1\n",
      "Epoch 882, global step 88300: 'train_loss' was not in top 1\n",
      "Epoch 883, global step 88400: 'train_loss' was not in top 1\n",
      "Epoch 884, global step 88500: 'train_loss' was not in top 1\n",
      "Epoch 885, global step 88600: 'train_loss' was not in top 1\n",
      "Epoch 886, global step 88700: 'train_loss' was not in top 1\n",
      "Epoch 887, global step 88800: 'train_loss' was not in top 1\n",
      "Epoch 888, global step 88900: 'train_loss' was not in top 1\n",
      "Epoch 889, global step 89000: 'train_loss' was not in top 1\n",
      "Epoch 890, global step 89100: 'train_loss' was not in top 1\n",
      "Epoch 891, global step 89200: 'train_loss' was not in top 1\n",
      "Epoch 892, global step 89300: 'train_loss' was not in top 1\n",
      "Epoch 893, global step 89400: 'train_loss' was not in top 1\n",
      "Epoch 894, global step 89500: 'train_loss' was not in top 1\n",
      "Epoch 895, global step 89600: 'train_loss' was not in top 1\n",
      "Epoch 896, global step 89700: 'train_loss' was not in top 1\n",
      "Epoch 897, global step 89800: 'train_loss' was not in top 1\n",
      "Epoch 898, global step 89900: 'train_loss' was not in top 1\n",
      "Epoch 899, global step 90000: 'train_loss' was not in top 1\n",
      "Epoch 900, global step 90100: 'train_loss' was not in top 1\n",
      "Epoch 901, global step 90200: 'train_loss' was not in top 1\n",
      "Epoch 902, global step 90300: 'train_loss' was not in top 1\n",
      "Epoch 903, global step 90400: 'train_loss' was not in top 1\n",
      "Epoch 904, global step 90500: 'train_loss' was not in top 1\n",
      "Epoch 905, global step 90600: 'train_loss' was not in top 1\n",
      "Epoch 906, global step 90700: 'train_loss' was not in top 1\n",
      "Epoch 907, global step 90800: 'train_loss' was not in top 1\n",
      "Epoch 908, global step 90900: 'train_loss' was not in top 1\n",
      "Epoch 909, global step 91000: 'train_loss' was not in top 1\n",
      "Epoch 910, global step 91100: 'train_loss' was not in top 1\n",
      "Epoch 911, global step 91200: 'train_loss' was not in top 1\n",
      "Epoch 912, global step 91300: 'train_loss' was not in top 1\n",
      "Epoch 913, global step 91400: 'train_loss' was not in top 1\n",
      "Epoch 914, global step 91500: 'train_loss' was not in top 1\n",
      "Epoch 915, global step 91600: 'train_loss' was not in top 1\n",
      "Epoch 916, global step 91700: 'train_loss' was not in top 1\n",
      "Epoch 917, global step 91800: 'train_loss' was not in top 1\n",
      "Epoch 918, global step 91900: 'train_loss' was not in top 1\n",
      "Epoch 919, global step 92000: 'train_loss' was not in top 1\n",
      "Epoch 920, global step 92100: 'train_loss' was not in top 1\n",
      "Epoch 921, global step 92200: 'train_loss' was not in top 1\n",
      "Epoch 922, global step 92300: 'train_loss' was not in top 1\n",
      "Epoch 923, global step 92400: 'train_loss' was not in top 1\n",
      "Epoch 924, global step 92500: 'train_loss' was not in top 1\n",
      "Epoch 925, global step 92600: 'train_loss' was not in top 1\n",
      "Epoch 926, global step 92700: 'train_loss' was not in top 1\n",
      "Epoch 927, global step 92800: 'train_loss' was not in top 1\n",
      "Epoch 928, global step 92900: 'train_loss' was not in top 1\n",
      "Epoch 929, global step 93000: 'train_loss' was not in top 1\n",
      "Epoch 930, global step 93100: 'train_loss' was not in top 1\n",
      "Epoch 931, global step 93200: 'train_loss' was not in top 1\n",
      "Epoch 932, global step 93300: 'train_loss' was not in top 1\n",
      "Epoch 933, global step 93400: 'train_loss' was not in top 1\n",
      "Epoch 934, global step 93500: 'train_loss' was not in top 1\n",
      "Epoch 935, global step 93600: 'train_loss' was not in top 1\n",
      "Epoch 936, global step 93700: 'train_loss' was not in top 1\n",
      "Epoch 937, global step 93800: 'train_loss' was not in top 1\n",
      "Epoch 938, global step 93900: 'train_loss' was not in top 1\n",
      "Epoch 939, global step 94000: 'train_loss' was not in top 1\n",
      "Epoch 940, global step 94100: 'train_loss' was not in top 1\n",
      "Epoch 941, global step 94200: 'train_loss' was not in top 1\n",
      "Epoch 942, global step 94300: 'train_loss' was not in top 1\n",
      "Epoch 943, global step 94400: 'train_loss' was not in top 1\n",
      "Epoch 944, global step 94500: 'train_loss' was not in top 1\n",
      "Epoch 945, global step 94600: 'train_loss' was not in top 1\n",
      "Epoch 946, global step 94700: 'train_loss' was not in top 1\n",
      "Epoch 947, global step 94800: 'train_loss' was not in top 1\n",
      "Epoch 948, global step 94900: 'train_loss' was not in top 1\n",
      "Epoch 949, global step 95000: 'train_loss' was not in top 1\n",
      "Epoch 950, global step 95100: 'train_loss' was not in top 1\n",
      "Epoch 951, global step 95200: 'train_loss' was not in top 1\n",
      "Epoch 952, global step 95300: 'train_loss' was not in top 1\n",
      "Epoch 953, global step 95400: 'train_loss' was not in top 1\n",
      "Epoch 954, global step 95500: 'train_loss' was not in top 1\n",
      "Epoch 955, global step 95600: 'train_loss' was not in top 1\n",
      "Epoch 956, global step 95700: 'train_loss' was not in top 1\n",
      "Epoch 957, global step 95800: 'train_loss' was not in top 1\n",
      "Epoch 958, global step 95900: 'train_loss' was not in top 1\n",
      "Epoch 959, global step 96000: 'train_loss' was not in top 1\n",
      "Epoch 960, global step 96100: 'train_loss' was not in top 1\n",
      "Epoch 961, global step 96200: 'train_loss' was not in top 1\n",
      "Epoch 962, global step 96300: 'train_loss' was not in top 1\n",
      "Epoch 963, global step 96400: 'train_loss' was not in top 1\n",
      "Epoch 964, global step 96500: 'train_loss' was not in top 1\n",
      "Epoch 965, global step 96600: 'train_loss' was not in top 1\n",
      "Epoch 966, global step 96700: 'train_loss' was not in top 1\n",
      "Epoch 967, global step 96800: 'train_loss' was not in top 1\n",
      "Epoch 968, global step 96900: 'train_loss' was not in top 1\n",
      "Epoch 969, global step 97000: 'train_loss' was not in top 1\n",
      "Epoch 970, global step 97100: 'train_loss' was not in top 1\n",
      "Epoch 971, global step 97200: 'train_loss' was not in top 1\n",
      "Epoch 972, global step 97300: 'train_loss' was not in top 1\n",
      "Epoch 973, global step 97400: 'train_loss' was not in top 1\n",
      "Epoch 974, global step 97500: 'train_loss' was not in top 1\n",
      "Epoch 975, global step 97600: 'train_loss' was not in top 1\n",
      "Epoch 976, global step 97700: 'train_loss' was not in top 1\n",
      "Epoch 977, global step 97800: 'train_loss' was not in top 1\n",
      "Epoch 978, global step 97900: 'train_loss' was not in top 1\n",
      "Epoch 979, global step 98000: 'train_loss' was not in top 1\n",
      "Epoch 980, global step 98100: 'train_loss' was not in top 1\n",
      "Epoch 981, global step 98200: 'train_loss' was not in top 1\n",
      "Epoch 982, global step 98300: 'train_loss' was not in top 1\n",
      "Epoch 983, global step 98400: 'train_loss' was not in top 1\n",
      "Epoch 984, global step 98500: 'train_loss' was not in top 1\n",
      "Epoch 985, global step 98600: 'train_loss' was not in top 1\n",
      "Epoch 986, global step 98700: 'train_loss' was not in top 1\n",
      "Epoch 987, global step 98800: 'train_loss' was not in top 1\n",
      "Epoch 988, global step 98900: 'train_loss' was not in top 1\n",
      "Epoch 989, global step 99000: 'train_loss' was not in top 1\n",
      "Epoch 990, global step 99100: 'train_loss' was not in top 1\n",
      "Epoch 991, global step 99200: 'train_loss' was not in top 1\n",
      "Epoch 992, global step 99300: 'train_loss' was not in top 1\n",
      "Epoch 993, global step 99400: 'train_loss' was not in top 1\n",
      "Epoch 994, global step 99500: 'train_loss' was not in top 1\n",
      "Epoch 995, global step 99600: 'train_loss' was not in top 1\n",
      "Epoch 996, global step 99700: 'train_loss' was not in top 1\n",
      "Epoch 997, global step 99800: 'train_loss' was not in top 1\n",
      "Epoch 998, global step 99900: 'train_loss' was not in top 1\n",
      "Epoch 999, global step 100000: 'train_loss' was not in top 1\n",
      "Epoch 1000, global step 100100: 'train_loss' was not in top 1\n",
      "Epoch 1001, global step 100200: 'train_loss' was not in top 1\n",
      "Epoch 1002, global step 100300: 'train_loss' was not in top 1\n",
      "Epoch 1003, global step 100400: 'train_loss' was not in top 1\n",
      "Epoch 1004, global step 100500: 'train_loss' was not in top 1\n",
      "Epoch 1005, global step 100600: 'train_loss' was not in top 1\n",
      "Epoch 1006, global step 100700: 'train_loss' was not in top 1\n",
      "Epoch 1007, global step 100800: 'train_loss' was not in top 1\n",
      "Epoch 1008, global step 100900: 'train_loss' was not in top 1\n",
      "Epoch 1009, global step 101000: 'train_loss' was not in top 1\n",
      "Epoch 1010, global step 101100: 'train_loss' was not in top 1\n",
      "Epoch 1011, global step 101200: 'train_loss' was not in top 1\n",
      "Epoch 1012, global step 101300: 'train_loss' was not in top 1\n",
      "Epoch 1013, global step 101400: 'train_loss' was not in top 1\n",
      "Epoch 1014, global step 101500: 'train_loss' was not in top 1\n",
      "Epoch 1015, global step 101600: 'train_loss' was not in top 1\n",
      "Epoch 1016, global step 101700: 'train_loss' was not in top 1\n",
      "Epoch 1017, global step 101800: 'train_loss' was not in top 1\n",
      "Epoch 1018, global step 101900: 'train_loss' was not in top 1\n",
      "Epoch 1019, global step 102000: 'train_loss' was not in top 1\n",
      "Epoch 1020, global step 102100: 'train_loss' was not in top 1\n",
      "Epoch 1021, global step 102200: 'train_loss' was not in top 1\n",
      "Epoch 1022, global step 102300: 'train_loss' was not in top 1\n",
      "Epoch 1023, global step 102400: 'train_loss' was not in top 1\n",
      "Epoch 1024, global step 102500: 'train_loss' was not in top 1\n",
      "Epoch 1025, global step 102600: 'train_loss' was not in top 1\n",
      "Epoch 1026, global step 102700: 'train_loss' was not in top 1\n",
      "Epoch 1027, global step 102800: 'train_loss' was not in top 1\n",
      "Epoch 1028, global step 102900: 'train_loss' was not in top 1\n",
      "Epoch 1029, global step 103000: 'train_loss' was not in top 1\n",
      "Epoch 1030, global step 103100: 'train_loss' was not in top 1\n",
      "Epoch 1031, global step 103200: 'train_loss' was not in top 1\n",
      "Epoch 1032, global step 103300: 'train_loss' was not in top 1\n",
      "Epoch 1033, global step 103400: 'train_loss' was not in top 1\n",
      "Epoch 1034, global step 103500: 'train_loss' was not in top 1\n",
      "Epoch 1035, global step 103600: 'train_loss' was not in top 1\n",
      "Epoch 1036, global step 103700: 'train_loss' was not in top 1\n",
      "Epoch 1037, global step 103800: 'train_loss' was not in top 1\n",
      "Epoch 1038, global step 103900: 'train_loss' was not in top 1\n",
      "Epoch 1039, global step 104000: 'train_loss' was not in top 1\n",
      "Epoch 1040, global step 104100: 'train_loss' was not in top 1\n",
      "Epoch 1041, global step 104200: 'train_loss' was not in top 1\n",
      "Epoch 1042, global step 104300: 'train_loss' was not in top 1\n",
      "Epoch 1043, global step 104400: 'train_loss' was not in top 1\n",
      "Epoch 1044, global step 104500: 'train_loss' was not in top 1\n",
      "Epoch 1045, global step 104600: 'train_loss' was not in top 1\n",
      "Epoch 1046, global step 104700: 'train_loss' was not in top 1\n",
      "Epoch 1047, global step 104800: 'train_loss' was not in top 1\n",
      "Epoch 1048, global step 104900: 'train_loss' was not in top 1\n",
      "Epoch 1049, global step 105000: 'train_loss' was not in top 1\n",
      "Epoch 1050, global step 105100: 'train_loss' was not in top 1\n",
      "Epoch 1051, global step 105200: 'train_loss' was not in top 1\n",
      "Epoch 1052, global step 105300: 'train_loss' was not in top 1\n",
      "Epoch 1053, global step 105400: 'train_loss' was not in top 1\n",
      "Epoch 1054, global step 105500: 'train_loss' was not in top 1\n",
      "Epoch 1055, global step 105600: 'train_loss' was not in top 1\n",
      "Epoch 1056, global step 105700: 'train_loss' was not in top 1\n",
      "Epoch 1057, global step 105800: 'train_loss' was not in top 1\n",
      "Epoch 1058, global step 105900: 'train_loss' was not in top 1\n",
      "Epoch 1059, global step 106000: 'train_loss' was not in top 1\n",
      "Epoch 1060, global step 106100: 'train_loss' was not in top 1\n",
      "Epoch 1061, global step 106200: 'train_loss' was not in top 1\n",
      "Epoch 1062, global step 106300: 'train_loss' was not in top 1\n",
      "Epoch 1063, global step 106400: 'train_loss' was not in top 1\n",
      "Epoch 1064, global step 106500: 'train_loss' was not in top 1\n",
      "Epoch 1065, global step 106600: 'train_loss' was not in top 1\n",
      "Epoch 1066, global step 106700: 'train_loss' was not in top 1\n",
      "Epoch 1067, global step 106800: 'train_loss' was not in top 1\n",
      "Epoch 1068, global step 106900: 'train_loss' was not in top 1\n",
      "Epoch 1069, global step 107000: 'train_loss' was not in top 1\n",
      "Epoch 1070, global step 107100: 'train_loss' was not in top 1\n",
      "Epoch 1071, global step 107200: 'train_loss' was not in top 1\n",
      "Epoch 1072, global step 107300: 'train_loss' was not in top 1\n",
      "Epoch 1073, global step 107400: 'train_loss' was not in top 1\n",
      "Epoch 1074, global step 107500: 'train_loss' was not in top 1\n",
      "Epoch 1075, global step 107600: 'train_loss' was not in top 1\n",
      "Epoch 1076, global step 107700: 'train_loss' was not in top 1\n",
      "Epoch 1077, global step 107800: 'train_loss' was not in top 1\n",
      "Epoch 1078, global step 107900: 'train_loss' was not in top 1\n",
      "Epoch 1079, global step 108000: 'train_loss' was not in top 1\n",
      "Epoch 1080, global step 108100: 'train_loss' was not in top 1\n",
      "Epoch 1081, global step 108200: 'train_loss' was not in top 1\n",
      "Epoch 1082, global step 108300: 'train_loss' was not in top 1\n",
      "Epoch 1083, global step 108400: 'train_loss' was not in top 1\n",
      "Epoch 1084, global step 108500: 'train_loss' was not in top 1\n",
      "Epoch 1085, global step 108600: 'train_loss' was not in top 1\n",
      "Epoch 1086, global step 108700: 'train_loss' was not in top 1\n",
      "Epoch 1087, global step 108800: 'train_loss' was not in top 1\n",
      "Epoch 1088, global step 108900: 'train_loss' was not in top 1\n",
      "Epoch 1089, global step 109000: 'train_loss' was not in top 1\n",
      "Epoch 1090, global step 109100: 'train_loss' was not in top 1\n",
      "Epoch 1091, global step 109200: 'train_loss' was not in top 1\n",
      "Epoch 1092, global step 109300: 'train_loss' was not in top 1\n",
      "Epoch 1093, global step 109400: 'train_loss' was not in top 1\n",
      "Epoch 1094, global step 109500: 'train_loss' was not in top 1\n",
      "Epoch 1095, global step 109600: 'train_loss' was not in top 1\n",
      "Epoch 1096, global step 109700: 'train_loss' was not in top 1\n",
      "Epoch 1097, global step 109800: 'train_loss' was not in top 1\n",
      "Epoch 1098, global step 109900: 'train_loss' was not in top 1\n",
      "Epoch 1099, global step 110000: 'train_loss' was not in top 1\n",
      "Epoch 1100, global step 110100: 'train_loss' was not in top 1\n",
      "Epoch 1101, global step 110200: 'train_loss' was not in top 1\n",
      "Epoch 1102, global step 110300: 'train_loss' was not in top 1\n",
      "Epoch 1103, global step 110400: 'train_loss' was not in top 1\n",
      "Epoch 1104, global step 110500: 'train_loss' was not in top 1\n",
      "Epoch 1105, global step 110600: 'train_loss' was not in top 1\n",
      "Epoch 1106, global step 110700: 'train_loss' was not in top 1\n",
      "Epoch 1107, global step 110800: 'train_loss' was not in top 1\n",
      "Epoch 1108, global step 110900: 'train_loss' was not in top 1\n",
      "Epoch 1109, global step 111000: 'train_loss' was not in top 1\n",
      "Epoch 1110, global step 111100: 'train_loss' was not in top 1\n",
      "Epoch 1111, global step 111200: 'train_loss' was not in top 1\n",
      "Epoch 1112, global step 111300: 'train_loss' was not in top 1\n",
      "Epoch 1113, global step 111400: 'train_loss' was not in top 1\n",
      "Epoch 1114, global step 111500: 'train_loss' was not in top 1\n",
      "Epoch 1115, global step 111600: 'train_loss' was not in top 1\n",
      "Epoch 1116, global step 111700: 'train_loss' was not in top 1\n",
      "Epoch 1117, global step 111800: 'train_loss' was not in top 1\n",
      "Epoch 1118, global step 111900: 'train_loss' was not in top 1\n",
      "Epoch 1119, global step 112000: 'train_loss' was not in top 1\n",
      "Epoch 1120, global step 112100: 'train_loss' was not in top 1\n",
      "Epoch 1121, global step 112200: 'train_loss' was not in top 1\n",
      "Epoch 1122, global step 112300: 'train_loss' was not in top 1\n",
      "Epoch 1123, global step 112400: 'train_loss' was not in top 1\n",
      "Epoch 1124, global step 112500: 'train_loss' was not in top 1\n",
      "Epoch 1125, global step 112600: 'train_loss' was not in top 1\n",
      "Epoch 1126, global step 112700: 'train_loss' was not in top 1\n",
      "Epoch 1127, global step 112800: 'train_loss' was not in top 1\n",
      "Epoch 1128, global step 112900: 'train_loss' was not in top 1\n",
      "Epoch 1129, global step 113000: 'train_loss' was not in top 1\n",
      "Epoch 1130, global step 113100: 'train_loss' was not in top 1\n",
      "Epoch 1131, global step 113200: 'train_loss' was not in top 1\n",
      "Epoch 1132, global step 113300: 'train_loss' was not in top 1\n",
      "Epoch 1133, global step 113400: 'train_loss' was not in top 1\n",
      "Epoch 1134, global step 113500: 'train_loss' was not in top 1\n",
      "Epoch 1135, global step 113600: 'train_loss' was not in top 1\n",
      "Epoch 1136, global step 113700: 'train_loss' was not in top 1\n",
      "Epoch 1137, global step 113800: 'train_loss' was not in top 1\n",
      "Epoch 1138, global step 113900: 'train_loss' was not in top 1\n",
      "Epoch 1139, global step 114000: 'train_loss' was not in top 1\n",
      "Epoch 1140, global step 114100: 'train_loss' was not in top 1\n",
      "Epoch 1141, global step 114200: 'train_loss' was not in top 1\n",
      "Epoch 1142, global step 114300: 'train_loss' was not in top 1\n",
      "Epoch 1143, global step 114400: 'train_loss' was not in top 1\n",
      "Epoch 1144, global step 114500: 'train_loss' was not in top 1\n",
      "Epoch 1145, global step 114600: 'train_loss' was not in top 1\n",
      "Epoch 1146, global step 114700: 'train_loss' was not in top 1\n",
      "Epoch 1147, global step 114800: 'train_loss' was not in top 1\n",
      "Epoch 1148, global step 114900: 'train_loss' was not in top 1\n",
      "Epoch 1149, global step 115000: 'train_loss' was not in top 1\n",
      "Epoch 1150, global step 115100: 'train_loss' was not in top 1\n",
      "Epoch 1151, global step 115200: 'train_loss' was not in top 1\n",
      "Epoch 1152, global step 115300: 'train_loss' was not in top 1\n",
      "Epoch 1153, global step 115400: 'train_loss' was not in top 1\n",
      "Epoch 1154, global step 115500: 'train_loss' was not in top 1\n",
      "Epoch 1155, global step 115600: 'train_loss' was not in top 1\n",
      "Epoch 1156, global step 115700: 'train_loss' was not in top 1\n",
      "Epoch 1157, global step 115800: 'train_loss' was not in top 1\n",
      "Epoch 1158, global step 115900: 'train_loss' was not in top 1\n",
      "Epoch 1159, global step 116000: 'train_loss' was not in top 1\n",
      "Epoch 1160, global step 116100: 'train_loss' was not in top 1\n",
      "Epoch 1161, global step 116200: 'train_loss' was not in top 1\n",
      "Epoch 1162, global step 116300: 'train_loss' was not in top 1\n",
      "Epoch 1163, global step 116400: 'train_loss' was not in top 1\n",
      "Epoch 1164, global step 116500: 'train_loss' was not in top 1\n",
      "Epoch 1165, global step 116600: 'train_loss' was not in top 1\n",
      "Epoch 1166, global step 116700: 'train_loss' was not in top 1\n",
      "Epoch 1167, global step 116800: 'train_loss' was not in top 1\n",
      "Epoch 1168, global step 116900: 'train_loss' was not in top 1\n",
      "Epoch 1169, global step 117000: 'train_loss' was not in top 1\n",
      "Epoch 1170, global step 117100: 'train_loss' was not in top 1\n",
      "Epoch 1171, global step 117200: 'train_loss' was not in top 1\n",
      "Epoch 1172, global step 117300: 'train_loss' was not in top 1\n",
      "Epoch 1173, global step 117400: 'train_loss' was not in top 1\n",
      "Epoch 1174, global step 117500: 'train_loss' was not in top 1\n",
      "Epoch 1175, global step 117600: 'train_loss' was not in top 1\n",
      "Epoch 1176, global step 117700: 'train_loss' was not in top 1\n",
      "Epoch 1177, global step 117800: 'train_loss' was not in top 1\n",
      "Epoch 1178, global step 117900: 'train_loss' was not in top 1\n",
      "Epoch 1179, global step 118000: 'train_loss' was not in top 1\n",
      "Epoch 1180, global step 118100: 'train_loss' was not in top 1\n",
      "Epoch 1181, global step 118200: 'train_loss' was not in top 1\n",
      "Epoch 1182, global step 118300: 'train_loss' was not in top 1\n",
      "Epoch 1183, global step 118400: 'train_loss' was not in top 1\n",
      "Epoch 1184, global step 118500: 'train_loss' was not in top 1\n",
      "Epoch 1185, global step 118600: 'train_loss' was not in top 1\n",
      "Epoch 1186, global step 118700: 'train_loss' was not in top 1\n",
      "Epoch 1187, global step 118800: 'train_loss' was not in top 1\n",
      "Epoch 1188, global step 118900: 'train_loss' was not in top 1\n",
      "Epoch 1189, global step 119000: 'train_loss' was not in top 1\n",
      "Epoch 1190, global step 119100: 'train_loss' was not in top 1\n",
      "Epoch 1191, global step 119200: 'train_loss' was not in top 1\n",
      "Epoch 1192, global step 119300: 'train_loss' was not in top 1\n",
      "Epoch 1193, global step 119400: 'train_loss' was not in top 1\n",
      "Epoch 1194, global step 119500: 'train_loss' was not in top 1\n",
      "Epoch 1195, global step 119600: 'train_loss' was not in top 1\n",
      "Epoch 1196, global step 119700: 'train_loss' was not in top 1\n",
      "Epoch 1197, global step 119800: 'train_loss' was not in top 1\n",
      "Epoch 1198, global step 119900: 'train_loss' was not in top 1\n",
      "Epoch 1199, global step 120000: 'train_loss' was not in top 1\n",
      "Epoch 1200, global step 120100: 'train_loss' was not in top 1\n",
      "Epoch 1201, global step 120200: 'train_loss' was not in top 1\n",
      "Epoch 1202, global step 120300: 'train_loss' was not in top 1\n",
      "Epoch 1203, global step 120400: 'train_loss' was not in top 1\n",
      "Epoch 1204, global step 120500: 'train_loss' was not in top 1\n",
      "Epoch 1205, global step 120600: 'train_loss' was not in top 1\n",
      "Epoch 1206, global step 120700: 'train_loss' was not in top 1\n",
      "Epoch 1207, global step 120800: 'train_loss' was not in top 1\n",
      "Epoch 1208, global step 120900: 'train_loss' was not in top 1\n",
      "Epoch 1209, global step 121000: 'train_loss' was not in top 1\n",
      "Epoch 1210, global step 121100: 'train_loss' was not in top 1\n",
      "Epoch 1211, global step 121200: 'train_loss' was not in top 1\n",
      "Epoch 1212, global step 121300: 'train_loss' was not in top 1\n",
      "Epoch 1213, global step 121400: 'train_loss' was not in top 1\n",
      "Epoch 1214, global step 121500: 'train_loss' was not in top 1\n",
      "Epoch 1215, global step 121600: 'train_loss' was not in top 1\n",
      "Epoch 1216, global step 121700: 'train_loss' was not in top 1\n",
      "Epoch 1217, global step 121800: 'train_loss' was not in top 1\n",
      "Epoch 1218, global step 121900: 'train_loss' was not in top 1\n",
      "Epoch 1219, global step 122000: 'train_loss' was not in top 1\n",
      "Epoch 1220, global step 122100: 'train_loss' was not in top 1\n",
      "Epoch 1221, global step 122200: 'train_loss' was not in top 1\n",
      "Epoch 1222, global step 122300: 'train_loss' was not in top 1\n",
      "Epoch 1223, global step 122400: 'train_loss' was not in top 1\n",
      "Epoch 1224, global step 122500: 'train_loss' was not in top 1\n",
      "Epoch 1225, global step 122600: 'train_loss' was not in top 1\n",
      "Epoch 1226, global step 122700: 'train_loss' was not in top 1\n",
      "Epoch 1227, global step 122800: 'train_loss' was not in top 1\n",
      "Epoch 1228, global step 122900: 'train_loss' was not in top 1\n",
      "Epoch 1229, global step 123000: 'train_loss' was not in top 1\n",
      "Epoch 1230, global step 123100: 'train_loss' was not in top 1\n",
      "Epoch 1231, global step 123200: 'train_loss' was not in top 1\n",
      "Epoch 1232, global step 123300: 'train_loss' was not in top 1\n",
      "Epoch 1233, global step 123400: 'train_loss' was not in top 1\n",
      "Epoch 1234, global step 123500: 'train_loss' was not in top 1\n",
      "Epoch 1235, global step 123600: 'train_loss' was not in top 1\n",
      "Epoch 1236, global step 123700: 'train_loss' was not in top 1\n",
      "Epoch 1237, global step 123800: 'train_loss' was not in top 1\n",
      "Epoch 1238, global step 123900: 'train_loss' was not in top 1\n",
      "Epoch 1239, global step 124000: 'train_loss' was not in top 1\n",
      "Epoch 1240, global step 124100: 'train_loss' was not in top 1\n",
      "Epoch 1241, global step 124200: 'train_loss' was not in top 1\n",
      "Epoch 1242, global step 124300: 'train_loss' was not in top 1\n",
      "Epoch 1243, global step 124400: 'train_loss' was not in top 1\n",
      "Epoch 1244, global step 124500: 'train_loss' was not in top 1\n",
      "Epoch 1245, global step 124600: 'train_loss' was not in top 1\n",
      "Epoch 1246, global step 124700: 'train_loss' was not in top 1\n",
      "Epoch 1247, global step 124800: 'train_loss' was not in top 1\n",
      "Epoch 1248, global step 124900: 'train_loss' was not in top 1\n",
      "Epoch 1249, global step 125000: 'train_loss' was not in top 1\n",
      "Epoch 1250, global step 125100: 'train_loss' was not in top 1\n",
      "Epoch 1251, global step 125200: 'train_loss' was not in top 1\n",
      "Epoch 1252, global step 125300: 'train_loss' was not in top 1\n",
      "Epoch 1253, global step 125400: 'train_loss' was not in top 1\n",
      "Epoch 1254, global step 125500: 'train_loss' was not in top 1\n",
      "Epoch 1255, global step 125600: 'train_loss' was not in top 1\n",
      "Epoch 1256, global step 125700: 'train_loss' was not in top 1\n",
      "Epoch 1257, global step 125800: 'train_loss' was not in top 1\n",
      "Epoch 1258, global step 125900: 'train_loss' was not in top 1\n",
      "Epoch 1259, global step 126000: 'train_loss' was not in top 1\n",
      "Epoch 1260, global step 126100: 'train_loss' was not in top 1\n",
      "Epoch 1261, global step 126200: 'train_loss' was not in top 1\n",
      "Epoch 1262, global step 126300: 'train_loss' was not in top 1\n",
      "Epoch 1263, global step 126400: 'train_loss' was not in top 1\n",
      "Epoch 1264, global step 126500: 'train_loss' was not in top 1\n",
      "Epoch 1265, global step 126600: 'train_loss' was not in top 1\n",
      "Epoch 1266, global step 126700: 'train_loss' was not in top 1\n",
      "Epoch 1267, global step 126800: 'train_loss' was not in top 1\n",
      "Epoch 1268, global step 126900: 'train_loss' was not in top 1\n",
      "Epoch 1269, global step 127000: 'train_loss' was not in top 1\n",
      "Epoch 1270, global step 127100: 'train_loss' was not in top 1\n",
      "Epoch 1271, global step 127200: 'train_loss' was not in top 1\n",
      "Epoch 1272, global step 127300: 'train_loss' was not in top 1\n",
      "Epoch 1273, global step 127400: 'train_loss' was not in top 1\n",
      "Epoch 1274, global step 127500: 'train_loss' was not in top 1\n",
      "Epoch 1275, global step 127600: 'train_loss' was not in top 1\n",
      "Epoch 1276, global step 127700: 'train_loss' was not in top 1\n",
      "Epoch 1277, global step 127800: 'train_loss' was not in top 1\n",
      "Epoch 1278, global step 127900: 'train_loss' was not in top 1\n",
      "Epoch 1279, global step 128000: 'train_loss' was not in top 1\n",
      "Epoch 1280, global step 128100: 'train_loss' was not in top 1\n",
      "Epoch 1281, global step 128200: 'train_loss' was not in top 1\n",
      "Epoch 1282, global step 128300: 'train_loss' was not in top 1\n",
      "Epoch 1283, global step 128400: 'train_loss' was not in top 1\n",
      "Epoch 1284, global step 128500: 'train_loss' was not in top 1\n",
      "Epoch 1285, global step 128600: 'train_loss' was not in top 1\n",
      "Epoch 1286, global step 128700: 'train_loss' was not in top 1\n",
      "Epoch 1287, global step 128800: 'train_loss' was not in top 1\n",
      "Epoch 1288, global step 128900: 'train_loss' was not in top 1\n",
      "Epoch 1289, global step 129000: 'train_loss' was not in top 1\n",
      "Epoch 1290, global step 129100: 'train_loss' was not in top 1\n",
      "Epoch 1291, global step 129200: 'train_loss' was not in top 1\n",
      "Epoch 1292, global step 129300: 'train_loss' was not in top 1\n",
      "Epoch 1293, global step 129400: 'train_loss' was not in top 1\n",
      "Epoch 1294, global step 129500: 'train_loss' was not in top 1\n",
      "Epoch 1295, global step 129600: 'train_loss' was not in top 1\n",
      "Epoch 1296, global step 129700: 'train_loss' was not in top 1\n",
      "Epoch 1297, global step 129800: 'train_loss' was not in top 1\n",
      "Epoch 1298, global step 129900: 'train_loss' was not in top 1\n",
      "Epoch 1299, global step 130000: 'train_loss' was not in top 1\n",
      "Epoch 1300, global step 130100: 'train_loss' was not in top 1\n",
      "Epoch 1301, global step 130200: 'train_loss' was not in top 1\n",
      "Epoch 1302, global step 130300: 'train_loss' was not in top 1\n",
      "Epoch 1303, global step 130400: 'train_loss' was not in top 1\n",
      "Epoch 1304, global step 130500: 'train_loss' was not in top 1\n",
      "Epoch 1305, global step 130600: 'train_loss' was not in top 1\n",
      "Epoch 1306, global step 130700: 'train_loss' was not in top 1\n",
      "Epoch 1307, global step 130800: 'train_loss' was not in top 1\n",
      "Epoch 1308, global step 130900: 'train_loss' was not in top 1\n",
      "Epoch 1309, global step 131000: 'train_loss' was not in top 1\n",
      "Epoch 1310, global step 131100: 'train_loss' was not in top 1\n",
      "Epoch 1311, global step 131200: 'train_loss' was not in top 1\n",
      "Epoch 1312, global step 131300: 'train_loss' was not in top 1\n",
      "Epoch 1313, global step 131400: 'train_loss' was not in top 1\n",
      "Epoch 1314, global step 131500: 'train_loss' was not in top 1\n",
      "Epoch 1315, global step 131600: 'train_loss' was not in top 1\n",
      "Epoch 1316, global step 131700: 'train_loss' was not in top 1\n",
      "Epoch 1317, global step 131800: 'train_loss' was not in top 1\n",
      "Epoch 1318, global step 131900: 'train_loss' was not in top 1\n",
      "Epoch 1319, global step 132000: 'train_loss' was not in top 1\n",
      "Epoch 1320, global step 132100: 'train_loss' was not in top 1\n",
      "Epoch 1321, global step 132200: 'train_loss' was not in top 1\n",
      "Epoch 1322, global step 132300: 'train_loss' was not in top 1\n",
      "Epoch 1323, global step 132400: 'train_loss' was not in top 1\n",
      "Epoch 1324, global step 132500: 'train_loss' was not in top 1\n",
      "Epoch 1325, global step 132600: 'train_loss' was not in top 1\n",
      "Epoch 1326, global step 132700: 'train_loss' was not in top 1\n",
      "Epoch 1327, global step 132800: 'train_loss' was not in top 1\n",
      "Epoch 1328, global step 132900: 'train_loss' was not in top 1\n",
      "Epoch 1329, global step 133000: 'train_loss' was not in top 1\n",
      "Epoch 1330, global step 133100: 'train_loss' was not in top 1\n",
      "Epoch 1331, global step 133200: 'train_loss' was not in top 1\n",
      "Epoch 1332, global step 133300: 'train_loss' was not in top 1\n",
      "Epoch 1333, global step 133400: 'train_loss' was not in top 1\n",
      "Epoch 1334, global step 133500: 'train_loss' was not in top 1\n",
      "Epoch 1335, global step 133600: 'train_loss' was not in top 1\n",
      "Epoch 1336, global step 133700: 'train_loss' was not in top 1\n",
      "Epoch 1337, global step 133800: 'train_loss' was not in top 1\n",
      "Epoch 1338, global step 133900: 'train_loss' was not in top 1\n",
      "Epoch 1339, global step 134000: 'train_loss' was not in top 1\n",
      "Epoch 1340, global step 134100: 'train_loss' was not in top 1\n",
      "Epoch 1341, global step 134200: 'train_loss' was not in top 1\n",
      "Epoch 1342, global step 134300: 'train_loss' was not in top 1\n",
      "Epoch 1343, global step 134400: 'train_loss' was not in top 1\n",
      "Epoch 1344, global step 134500: 'train_loss' was not in top 1\n",
      "Epoch 1345, global step 134600: 'train_loss' was not in top 1\n",
      "Epoch 1346, global step 134700: 'train_loss' was not in top 1\n",
      "Epoch 1347, global step 134800: 'train_loss' was not in top 1\n",
      "Epoch 1348, global step 134900: 'train_loss' was not in top 1\n",
      "Epoch 1349, global step 135000: 'train_loss' was not in top 1\n",
      "Epoch 1350, global step 135100: 'train_loss' was not in top 1\n",
      "Epoch 1351, global step 135200: 'train_loss' was not in top 1\n",
      "Epoch 1352, global step 135300: 'train_loss' was not in top 1\n",
      "Epoch 1353, global step 135400: 'train_loss' was not in top 1\n",
      "Epoch 1354, global step 135500: 'train_loss' was not in top 1\n",
      "Epoch 1355, global step 135600: 'train_loss' was not in top 1\n",
      "Epoch 1356, global step 135700: 'train_loss' was not in top 1\n",
      "Epoch 1357, global step 135800: 'train_loss' was not in top 1\n",
      "Epoch 1358, global step 135900: 'train_loss' was not in top 1\n",
      "Epoch 1359, global step 136000: 'train_loss' was not in top 1\n",
      "Epoch 1360, global step 136100: 'train_loss' was not in top 1\n",
      "Epoch 1361, global step 136200: 'train_loss' was not in top 1\n",
      "Epoch 1362, global step 136300: 'train_loss' was not in top 1\n",
      "Epoch 1363, global step 136400: 'train_loss' was not in top 1\n",
      "Epoch 1364, global step 136500: 'train_loss' was not in top 1\n",
      "Epoch 1365, global step 136600: 'train_loss' was not in top 1\n",
      "Epoch 1366, global step 136700: 'train_loss' was not in top 1\n",
      "Epoch 1367, global step 136800: 'train_loss' was not in top 1\n",
      "Epoch 1368, global step 136900: 'train_loss' was not in top 1\n",
      "Epoch 1369, global step 137000: 'train_loss' was not in top 1\n",
      "Epoch 1370, global step 137100: 'train_loss' was not in top 1\n",
      "Epoch 1371, global step 137200: 'train_loss' was not in top 1\n",
      "Epoch 1372, global step 137300: 'train_loss' was not in top 1\n",
      "Epoch 1373, global step 137400: 'train_loss' was not in top 1\n",
      "Epoch 1374, global step 137500: 'train_loss' was not in top 1\n",
      "Epoch 1375, global step 137600: 'train_loss' was not in top 1\n",
      "Epoch 1376, global step 137700: 'train_loss' was not in top 1\n",
      "Epoch 1377, global step 137800: 'train_loss' was not in top 1\n",
      "Epoch 1378, global step 137900: 'train_loss' was not in top 1\n",
      "Epoch 1379, global step 138000: 'train_loss' was not in top 1\n",
      "Epoch 1380, global step 138100: 'train_loss' was not in top 1\n",
      "Epoch 1381, global step 138200: 'train_loss' was not in top 1\n",
      "Epoch 1382, global step 138300: 'train_loss' was not in top 1\n",
      "Epoch 1383, global step 138400: 'train_loss' was not in top 1\n",
      "Epoch 1384, global step 138500: 'train_loss' was not in top 1\n",
      "Epoch 1385, global step 138600: 'train_loss' was not in top 1\n",
      "Epoch 1386, global step 138700: 'train_loss' was not in top 1\n",
      "Epoch 1387, global step 138800: 'train_loss' was not in top 1\n",
      "Epoch 1388, global step 138900: 'train_loss' was not in top 1\n",
      "Epoch 1389, global step 139000: 'train_loss' was not in top 1\n",
      "Epoch 1390, global step 139100: 'train_loss' was not in top 1\n",
      "Epoch 1391, global step 139200: 'train_loss' was not in top 1\n",
      "Epoch 1392, global step 139300: 'train_loss' was not in top 1\n",
      "Epoch 1393, global step 139400: 'train_loss' was not in top 1\n",
      "Epoch 1394, global step 139500: 'train_loss' was not in top 1\n",
      "Epoch 1395, global step 139600: 'train_loss' was not in top 1\n",
      "Epoch 1396, global step 139700: 'train_loss' was not in top 1\n",
      "Epoch 1397, global step 139800: 'train_loss' was not in top 1\n",
      "Epoch 1398, global step 139900: 'train_loss' was not in top 1\n",
      "Epoch 1399, global step 140000: 'train_loss' was not in top 1\n",
      "Epoch 1400, global step 140100: 'train_loss' was not in top 1\n",
      "Epoch 1401, global step 140200: 'train_loss' was not in top 1\n",
      "Epoch 1402, global step 140300: 'train_loss' was not in top 1\n",
      "Epoch 1403, global step 140400: 'train_loss' was not in top 1\n",
      "Epoch 1404, global step 140500: 'train_loss' was not in top 1\n",
      "Epoch 1405, global step 140600: 'train_loss' was not in top 1\n",
      "Epoch 1406, global step 140700: 'train_loss' was not in top 1\n",
      "Epoch 1407, global step 140800: 'train_loss' was not in top 1\n",
      "Epoch 1408, global step 140900: 'train_loss' was not in top 1\n",
      "Epoch 1409, global step 141000: 'train_loss' was not in top 1\n",
      "Epoch 1410, global step 141100: 'train_loss' was not in top 1\n",
      "Epoch 1411, global step 141200: 'train_loss' was not in top 1\n",
      "Epoch 1412, global step 141300: 'train_loss' was not in top 1\n",
      "Epoch 1413, global step 141400: 'train_loss' was not in top 1\n",
      "Epoch 1414, global step 141500: 'train_loss' was not in top 1\n",
      "Epoch 1415, global step 141600: 'train_loss' was not in top 1\n",
      "Epoch 1416, global step 141700: 'train_loss' was not in top 1\n",
      "Epoch 1417, global step 141800: 'train_loss' was not in top 1\n",
      "Epoch 1418, global step 141900: 'train_loss' was not in top 1\n",
      "Epoch 1419, global step 142000: 'train_loss' was not in top 1\n",
      "Epoch 1420, global step 142100: 'train_loss' was not in top 1\n",
      "Epoch 1421, global step 142200: 'train_loss' was not in top 1\n",
      "Epoch 1422, global step 142300: 'train_loss' was not in top 1\n",
      "Epoch 1423, global step 142400: 'train_loss' was not in top 1\n",
      "Epoch 1424, global step 142500: 'train_loss' was not in top 1\n",
      "Epoch 1425, global step 142600: 'train_loss' was not in top 1\n",
      "Epoch 1426, global step 142700: 'train_loss' was not in top 1\n",
      "Epoch 1427, global step 142800: 'train_loss' was not in top 1\n",
      "Epoch 1428, global step 142900: 'train_loss' was not in top 1\n",
      "Epoch 1429, global step 143000: 'train_loss' was not in top 1\n",
      "Epoch 1430, global step 143100: 'train_loss' was not in top 1\n",
      "Epoch 1431, global step 143200: 'train_loss' was not in top 1\n",
      "Epoch 1432, global step 143300: 'train_loss' was not in top 1\n",
      "Epoch 1433, global step 143400: 'train_loss' was not in top 1\n",
      "Epoch 1434, global step 143500: 'train_loss' was not in top 1\n",
      "Epoch 1435, global step 143600: 'train_loss' was not in top 1\n",
      "Epoch 1436, global step 143700: 'train_loss' was not in top 1\n",
      "Epoch 1437, global step 143800: 'train_loss' was not in top 1\n",
      "Epoch 1438, global step 143900: 'train_loss' was not in top 1\n",
      "Epoch 1439, global step 144000: 'train_loss' was not in top 1\n",
      "Epoch 1440, global step 144100: 'train_loss' was not in top 1\n",
      "Epoch 1441, global step 144200: 'train_loss' was not in top 1\n",
      "Epoch 1442, global step 144300: 'train_loss' was not in top 1\n",
      "Epoch 1443, global step 144400: 'train_loss' was not in top 1\n",
      "Epoch 1444, global step 144500: 'train_loss' was not in top 1\n",
      "Epoch 1445, global step 144600: 'train_loss' was not in top 1\n",
      "Epoch 1446, global step 144700: 'train_loss' was not in top 1\n",
      "Epoch 1447, global step 144800: 'train_loss' was not in top 1\n",
      "Epoch 1448, global step 144900: 'train_loss' was not in top 1\n",
      "Epoch 1449, global step 145000: 'train_loss' was not in top 1\n",
      "Epoch 1450, global step 145100: 'train_loss' was not in top 1\n",
      "Epoch 1451, global step 145200: 'train_loss' was not in top 1\n",
      "Epoch 1452, global step 145300: 'train_loss' was not in top 1\n",
      "Epoch 1453, global step 145400: 'train_loss' was not in top 1\n",
      "Epoch 1454, global step 145500: 'train_loss' was not in top 1\n",
      "Epoch 1455, global step 145600: 'train_loss' was not in top 1\n",
      "Epoch 1456, global step 145700: 'train_loss' was not in top 1\n",
      "Epoch 1457, global step 145800: 'train_loss' was not in top 1\n",
      "Epoch 1458, global step 145900: 'train_loss' was not in top 1\n",
      "Epoch 1459, global step 146000: 'train_loss' was not in top 1\n",
      "Epoch 1460, global step 146100: 'train_loss' was not in top 1\n",
      "Epoch 1461, global step 146200: 'train_loss' was not in top 1\n",
      "Epoch 1462, global step 146300: 'train_loss' was not in top 1\n",
      "Epoch 1463, global step 146400: 'train_loss' was not in top 1\n",
      "Epoch 1464, global step 146500: 'train_loss' was not in top 1\n",
      "Epoch 1465, global step 146600: 'train_loss' was not in top 1\n",
      "Epoch 1466, global step 146700: 'train_loss' was not in top 1\n",
      "Epoch 1467, global step 146800: 'train_loss' was not in top 1\n",
      "Epoch 1468, global step 146900: 'train_loss' was not in top 1\n",
      "Epoch 1469, global step 147000: 'train_loss' was not in top 1\n",
      "Epoch 1470, global step 147100: 'train_loss' was not in top 1\n",
      "Epoch 1471, global step 147200: 'train_loss' was not in top 1\n",
      "Epoch 1472, global step 147300: 'train_loss' was not in top 1\n",
      "Epoch 1473, global step 147400: 'train_loss' was not in top 1\n",
      "Epoch 1474, global step 147500: 'train_loss' was not in top 1\n",
      "Epoch 1475, global step 147600: 'train_loss' was not in top 1\n",
      "Epoch 1476, global step 147700: 'train_loss' was not in top 1\n",
      "Epoch 1477, global step 147800: 'train_loss' was not in top 1\n",
      "Epoch 1478, global step 147900: 'train_loss' was not in top 1\n",
      "Epoch 1479, global step 148000: 'train_loss' was not in top 1\n",
      "Epoch 1480, global step 148100: 'train_loss' was not in top 1\n",
      "Epoch 1481, global step 148200: 'train_loss' was not in top 1\n",
      "Epoch 1482, global step 148300: 'train_loss' was not in top 1\n",
      "Epoch 1483, global step 148400: 'train_loss' was not in top 1\n",
      "Epoch 1484, global step 148500: 'train_loss' was not in top 1\n",
      "Epoch 1485, global step 148600: 'train_loss' was not in top 1\n",
      "Epoch 1486, global step 148700: 'train_loss' was not in top 1\n",
      "Epoch 1487, global step 148800: 'train_loss' was not in top 1\n",
      "Epoch 1488, global step 148900: 'train_loss' was not in top 1\n",
      "Epoch 1489, global step 149000: 'train_loss' was not in top 1\n",
      "Epoch 1490, global step 149100: 'train_loss' was not in top 1\n",
      "Epoch 1491, global step 149200: 'train_loss' was not in top 1\n",
      "Epoch 1492, global step 149300: 'train_loss' was not in top 1\n",
      "Epoch 1493, global step 149400: 'train_loss' was not in top 1\n",
      "Epoch 1494, global step 149500: 'train_loss' was not in top 1\n",
      "Epoch 1495, global step 149600: 'train_loss' was not in top 1\n",
      "Epoch 1496, global step 149700: 'train_loss' was not in top 1\n",
      "Epoch 1497, global step 149800: 'train_loss' was not in top 1\n",
      "Epoch 1498, global step 149900: 'train_loss' was not in top 1\n",
      "Epoch 1499, global step 150000: 'train_loss' was not in top 1\n",
      "Epoch 1500, global step 150100: 'train_loss' was not in top 1\n",
      "Epoch 1501, global step 150200: 'train_loss' was not in top 1\n",
      "Epoch 1502, global step 150300: 'train_loss' was not in top 1\n",
      "Epoch 1503, global step 150400: 'train_loss' was not in top 1\n",
      "Epoch 1504, global step 150500: 'train_loss' was not in top 1\n",
      "Epoch 1505, global step 150600: 'train_loss' was not in top 1\n",
      "Epoch 1506, global step 150700: 'train_loss' was not in top 1\n",
      "Epoch 1507, global step 150800: 'train_loss' was not in top 1\n",
      "Epoch 1508, global step 150900: 'train_loss' was not in top 1\n",
      "Epoch 1509, global step 151000: 'train_loss' was not in top 1\n",
      "Epoch 1510, global step 151100: 'train_loss' was not in top 1\n",
      "Epoch 1511, global step 151200: 'train_loss' was not in top 1\n",
      "Epoch 1512, global step 151300: 'train_loss' was not in top 1\n",
      "Epoch 1513, global step 151400: 'train_loss' was not in top 1\n",
      "Epoch 1514, global step 151500: 'train_loss' was not in top 1\n",
      "Epoch 1515, global step 151600: 'train_loss' was not in top 1\n",
      "Epoch 1516, global step 151700: 'train_loss' was not in top 1\n",
      "Epoch 1517, global step 151800: 'train_loss' was not in top 1\n",
      "Epoch 1518, global step 151900: 'train_loss' was not in top 1\n",
      "Epoch 1519, global step 152000: 'train_loss' was not in top 1\n",
      "Epoch 1520, global step 152100: 'train_loss' was not in top 1\n",
      "Epoch 1521, global step 152200: 'train_loss' was not in top 1\n",
      "Epoch 1522, global step 152300: 'train_loss' was not in top 1\n",
      "Epoch 1523, global step 152400: 'train_loss' was not in top 1\n",
      "Epoch 1524, global step 152500: 'train_loss' was not in top 1\n",
      "Epoch 1525, global step 152600: 'train_loss' was not in top 1\n",
      "Epoch 1526, global step 152700: 'train_loss' was not in top 1\n",
      "Epoch 1527, global step 152800: 'train_loss' was not in top 1\n",
      "Epoch 1528, global step 152900: 'train_loss' was not in top 1\n",
      "Epoch 1529, global step 153000: 'train_loss' was not in top 1\n",
      "Epoch 1530, global step 153100: 'train_loss' was not in top 1\n",
      "Epoch 1531, global step 153200: 'train_loss' was not in top 1\n",
      "Epoch 1532, global step 153300: 'train_loss' was not in top 1\n",
      "Epoch 1533, global step 153400: 'train_loss' was not in top 1\n",
      "Epoch 1534, global step 153500: 'train_loss' was not in top 1\n",
      "Epoch 1535, global step 153600: 'train_loss' was not in top 1\n",
      "Epoch 1536, global step 153700: 'train_loss' was not in top 1\n",
      "Epoch 1537, global step 153800: 'train_loss' was not in top 1\n",
      "Epoch 1538, global step 153900: 'train_loss' was not in top 1\n",
      "Epoch 1539, global step 154000: 'train_loss' was not in top 1\n",
      "Epoch 1540, global step 154100: 'train_loss' was not in top 1\n",
      "Epoch 1541, global step 154200: 'train_loss' was not in top 1\n",
      "Epoch 1542, global step 154300: 'train_loss' was not in top 1\n",
      "Epoch 1543, global step 154400: 'train_loss' was not in top 1\n",
      "Epoch 1544, global step 154500: 'train_loss' was not in top 1\n",
      "Epoch 1545, global step 154600: 'train_loss' was not in top 1\n",
      "Epoch 1546, global step 154700: 'train_loss' was not in top 1\n",
      "Epoch 1547, global step 154800: 'train_loss' was not in top 1\n",
      "Epoch 1548, global step 154900: 'train_loss' was not in top 1\n",
      "Epoch 1549, global step 155000: 'train_loss' was not in top 1\n",
      "Epoch 1550, global step 155100: 'train_loss' was not in top 1\n",
      "Epoch 1551, global step 155200: 'train_loss' was not in top 1\n",
      "Epoch 1552, global step 155300: 'train_loss' was not in top 1\n",
      "Epoch 1553, global step 155400: 'train_loss' was not in top 1\n",
      "Epoch 1554, global step 155500: 'train_loss' was not in top 1\n",
      "Epoch 1555, global step 155600: 'train_loss' was not in top 1\n",
      "Epoch 1556, global step 155700: 'train_loss' was not in top 1\n",
      "Epoch 1557, global step 155800: 'train_loss' was not in top 1\n",
      "Epoch 1558, global step 155900: 'train_loss' was not in top 1\n",
      "Epoch 1559, global step 156000: 'train_loss' was not in top 1\n",
      "Epoch 1560, global step 156100: 'train_loss' was not in top 1\n",
      "Epoch 1561, global step 156200: 'train_loss' was not in top 1\n",
      "Epoch 1562, global step 156300: 'train_loss' was not in top 1\n",
      "Epoch 1563, global step 156400: 'train_loss' was not in top 1\n",
      "Epoch 1564, global step 156500: 'train_loss' was not in top 1\n",
      "Epoch 1565, global step 156600: 'train_loss' was not in top 1\n",
      "Epoch 1566, global step 156700: 'train_loss' was not in top 1\n",
      "Epoch 1567, global step 156800: 'train_loss' was not in top 1\n",
      "Epoch 1568, global step 156900: 'train_loss' was not in top 1\n",
      "Epoch 1569, global step 157000: 'train_loss' was not in top 1\n",
      "Epoch 1570, global step 157100: 'train_loss' was not in top 1\n",
      "Epoch 1571, global step 157200: 'train_loss' was not in top 1\n",
      "Epoch 1572, global step 157300: 'train_loss' was not in top 1\n",
      "Epoch 1573, global step 157400: 'train_loss' was not in top 1\n",
      "Epoch 1574, global step 157500: 'train_loss' was not in top 1\n",
      "Epoch 1575, global step 157600: 'train_loss' was not in top 1\n",
      "Epoch 1576, global step 157700: 'train_loss' was not in top 1\n",
      "Epoch 1577, global step 157800: 'train_loss' was not in top 1\n",
      "Epoch 1578, global step 157900: 'train_loss' was not in top 1\n",
      "Epoch 1579, global step 158000: 'train_loss' was not in top 1\n",
      "Epoch 1580, global step 158100: 'train_loss' was not in top 1\n",
      "Epoch 1581, global step 158200: 'train_loss' was not in top 1\n",
      "Epoch 1582, global step 158300: 'train_loss' was not in top 1\n",
      "Epoch 1583, global step 158400: 'train_loss' was not in top 1\n",
      "Epoch 1584, global step 158500: 'train_loss' was not in top 1\n",
      "Epoch 1585, global step 158600: 'train_loss' was not in top 1\n",
      "Epoch 1586, global step 158700: 'train_loss' was not in top 1\n",
      "Epoch 1587, global step 158800: 'train_loss' was not in top 1\n",
      "Epoch 1588, global step 158900: 'train_loss' was not in top 1\n",
      "Epoch 1589, global step 159000: 'train_loss' was not in top 1\n",
      "Epoch 1590, global step 159100: 'train_loss' was not in top 1\n",
      "Epoch 1591, global step 159200: 'train_loss' was not in top 1\n",
      "Epoch 1592, global step 159300: 'train_loss' was not in top 1\n",
      "Epoch 1593, global step 159400: 'train_loss' was not in top 1\n",
      "Epoch 1594, global step 159500: 'train_loss' was not in top 1\n",
      "Epoch 1595, global step 159600: 'train_loss' was not in top 1\n",
      "Epoch 1596, global step 159700: 'train_loss' was not in top 1\n",
      "Epoch 1597, global step 159800: 'train_loss' was not in top 1\n",
      "Epoch 1598, global step 159900: 'train_loss' was not in top 1\n",
      "Epoch 1599, global step 160000: 'train_loss' was not in top 1\n",
      "Epoch 1600, global step 160100: 'train_loss' was not in top 1\n",
      "Epoch 1601, global step 160200: 'train_loss' was not in top 1\n",
      "Epoch 1602, global step 160300: 'train_loss' was not in top 1\n",
      "Epoch 1603, global step 160400: 'train_loss' was not in top 1\n",
      "Epoch 1604, global step 160500: 'train_loss' was not in top 1\n",
      "Epoch 1605, global step 160600: 'train_loss' was not in top 1\n",
      "Epoch 1606, global step 160700: 'train_loss' was not in top 1\n",
      "Epoch 1607, global step 160800: 'train_loss' was not in top 1\n",
      "Epoch 1608, global step 160900: 'train_loss' was not in top 1\n",
      "Epoch 1609, global step 161000: 'train_loss' was not in top 1\n",
      "Epoch 1610, global step 161100: 'train_loss' was not in top 1\n",
      "Epoch 1611, global step 161200: 'train_loss' was not in top 1\n",
      "Epoch 1612, global step 161300: 'train_loss' was not in top 1\n",
      "Epoch 1613, global step 161400: 'train_loss' was not in top 1\n",
      "Epoch 1614, global step 161500: 'train_loss' was not in top 1\n",
      "Epoch 1615, global step 161600: 'train_loss' was not in top 1\n",
      "Epoch 1616, global step 161700: 'train_loss' was not in top 1\n",
      "Epoch 1617, global step 161800: 'train_loss' was not in top 1\n",
      "Epoch 1618, global step 161900: 'train_loss' was not in top 1\n",
      "Epoch 1619, global step 162000: 'train_loss' was not in top 1\n",
      "Epoch 1620, global step 162100: 'train_loss' was not in top 1\n",
      "Epoch 1621, global step 162200: 'train_loss' was not in top 1\n",
      "Epoch 1622, global step 162300: 'train_loss' was not in top 1\n",
      "Epoch 1623, global step 162400: 'train_loss' was not in top 1\n",
      "Epoch 1624, global step 162500: 'train_loss' was not in top 1\n",
      "Epoch 1625, global step 162600: 'train_loss' was not in top 1\n",
      "Epoch 1626, global step 162700: 'train_loss' was not in top 1\n",
      "Epoch 1627, global step 162800: 'train_loss' was not in top 1\n",
      "Epoch 1628, global step 162900: 'train_loss' was not in top 1\n",
      "Epoch 1629, global step 163000: 'train_loss' was not in top 1\n",
      "Epoch 1630, global step 163100: 'train_loss' was not in top 1\n",
      "Epoch 1631, global step 163200: 'train_loss' was not in top 1\n",
      "Epoch 1632, global step 163300: 'train_loss' was not in top 1\n",
      "Epoch 1633, global step 163400: 'train_loss' was not in top 1\n",
      "Epoch 1634, global step 163500: 'train_loss' was not in top 1\n",
      "Epoch 1635, global step 163600: 'train_loss' was not in top 1\n",
      "Epoch 1636, global step 163700: 'train_loss' was not in top 1\n",
      "Epoch 1637, global step 163800: 'train_loss' was not in top 1\n",
      "Epoch 1638, global step 163900: 'train_loss' was not in top 1\n",
      "Epoch 1639, global step 164000: 'train_loss' was not in top 1\n",
      "Epoch 1640, global step 164100: 'train_loss' was not in top 1\n",
      "Epoch 1641, global step 164200: 'train_loss' was not in top 1\n",
      "Epoch 1642, global step 164300: 'train_loss' was not in top 1\n",
      "Epoch 1643, global step 164400: 'train_loss' was not in top 1\n",
      "Epoch 1644, global step 164500: 'train_loss' was not in top 1\n",
      "Epoch 1645, global step 164600: 'train_loss' was not in top 1\n",
      "Epoch 1646, global step 164700: 'train_loss' was not in top 1\n",
      "Epoch 1647, global step 164800: 'train_loss' was not in top 1\n",
      "Epoch 1648, global step 164900: 'train_loss' was not in top 1\n",
      "Epoch 1649, global step 165000: 'train_loss' was not in top 1\n",
      "Epoch 1650, global step 165100: 'train_loss' was not in top 1\n",
      "Epoch 1651, global step 165200: 'train_loss' was not in top 1\n",
      "Epoch 1652, global step 165300: 'train_loss' was not in top 1\n",
      "Epoch 1653, global step 165400: 'train_loss' was not in top 1\n",
      "Epoch 1654, global step 165500: 'train_loss' was not in top 1\n",
      "Epoch 1655, global step 165600: 'train_loss' was not in top 1\n",
      "Epoch 1656, global step 165700: 'train_loss' was not in top 1\n",
      "Epoch 1657, global step 165800: 'train_loss' was not in top 1\n",
      "Epoch 1658, global step 165900: 'train_loss' was not in top 1\n",
      "Epoch 1659, global step 166000: 'train_loss' was not in top 1\n",
      "Epoch 1660, global step 166100: 'train_loss' was not in top 1\n",
      "Epoch 1661, global step 166200: 'train_loss' was not in top 1\n",
      "Epoch 1662, global step 166300: 'train_loss' was not in top 1\n",
      "Epoch 1663, global step 166400: 'train_loss' was not in top 1\n",
      "Epoch 1664, global step 166500: 'train_loss' was not in top 1\n",
      "Epoch 1665, global step 166600: 'train_loss' was not in top 1\n",
      "Epoch 1666, global step 166700: 'train_loss' was not in top 1\n",
      "Epoch 1667, global step 166800: 'train_loss' was not in top 1\n",
      "Epoch 1668, global step 166900: 'train_loss' was not in top 1\n",
      "Epoch 1669, global step 167000: 'train_loss' was not in top 1\n",
      "Epoch 1670, global step 167100: 'train_loss' was not in top 1\n",
      "Epoch 1671, global step 167200: 'train_loss' was not in top 1\n",
      "Epoch 1672, global step 167300: 'train_loss' was not in top 1\n",
      "Epoch 1673, global step 167400: 'train_loss' was not in top 1\n",
      "Epoch 1674, global step 167500: 'train_loss' was not in top 1\n",
      "Epoch 1675, global step 167600: 'train_loss' was not in top 1\n",
      "Epoch 1676, global step 167700: 'train_loss' was not in top 1\n",
      "Epoch 1677, global step 167800: 'train_loss' was not in top 1\n",
      "Epoch 1678, global step 167900: 'train_loss' was not in top 1\n",
      "Epoch 1679, global step 168000: 'train_loss' was not in top 1\n",
      "Epoch 1680, global step 168100: 'train_loss' was not in top 1\n",
      "Epoch 1681, global step 168200: 'train_loss' was not in top 1\n",
      "Epoch 1682, global step 168300: 'train_loss' was not in top 1\n",
      "Epoch 1683, global step 168400: 'train_loss' was not in top 1\n",
      "Epoch 1684, global step 168500: 'train_loss' was not in top 1\n",
      "Epoch 1685, global step 168600: 'train_loss' was not in top 1\n",
      "Epoch 1686, global step 168700: 'train_loss' was not in top 1\n",
      "Epoch 1687, global step 168800: 'train_loss' was not in top 1\n",
      "Epoch 1688, global step 168900: 'train_loss' was not in top 1\n",
      "Epoch 1689, global step 169000: 'train_loss' was not in top 1\n",
      "Epoch 1690, global step 169100: 'train_loss' was not in top 1\n",
      "Epoch 1691, global step 169200: 'train_loss' was not in top 1\n",
      "Epoch 1692, global step 169300: 'train_loss' was not in top 1\n",
      "Epoch 1693, global step 169400: 'train_loss' was not in top 1\n",
      "Epoch 1694, global step 169500: 'train_loss' was not in top 1\n",
      "Epoch 1695, global step 169600: 'train_loss' was not in top 1\n",
      "Epoch 1696, global step 169700: 'train_loss' was not in top 1\n",
      "Epoch 1697, global step 169800: 'train_loss' was not in top 1\n",
      "Epoch 1698, global step 169900: 'train_loss' was not in top 1\n",
      "Epoch 1699, global step 170000: 'train_loss' was not in top 1\n",
      "Epoch 1700, global step 170100: 'train_loss' was not in top 1\n",
      "Epoch 1701, global step 170200: 'train_loss' was not in top 1\n",
      "Epoch 1702, global step 170300: 'train_loss' was not in top 1\n",
      "Epoch 1703, global step 170400: 'train_loss' was not in top 1\n",
      "Epoch 1704, global step 170500: 'train_loss' was not in top 1\n",
      "Epoch 1705, global step 170600: 'train_loss' was not in top 1\n",
      "Epoch 1706, global step 170700: 'train_loss' was not in top 1\n",
      "Epoch 1707, global step 170800: 'train_loss' was not in top 1\n",
      "Epoch 1708, global step 170900: 'train_loss' was not in top 1\n",
      "Epoch 1709, global step 171000: 'train_loss' was not in top 1\n",
      "Epoch 1710, global step 171100: 'train_loss' was not in top 1\n",
      "Epoch 1711, global step 171200: 'train_loss' was not in top 1\n",
      "Epoch 1712, global step 171300: 'train_loss' was not in top 1\n",
      "Epoch 1713, global step 171400: 'train_loss' was not in top 1\n",
      "Epoch 1714, global step 171500: 'train_loss' was not in top 1\n",
      "Epoch 1715, global step 171600: 'train_loss' was not in top 1\n",
      "Epoch 1716, global step 171700: 'train_loss' was not in top 1\n",
      "Epoch 1717, global step 171800: 'train_loss' was not in top 1\n",
      "Epoch 1718, global step 171900: 'train_loss' was not in top 1\n",
      "Epoch 1719, global step 172000: 'train_loss' was not in top 1\n",
      "Epoch 1720, global step 172100: 'train_loss' was not in top 1\n",
      "Epoch 1721, global step 172200: 'train_loss' was not in top 1\n",
      "Epoch 1722, global step 172300: 'train_loss' was not in top 1\n",
      "Epoch 1723, global step 172400: 'train_loss' was not in top 1\n",
      "Epoch 1724, global step 172500: 'train_loss' was not in top 1\n",
      "Epoch 1725, global step 172600: 'train_loss' was not in top 1\n",
      "Epoch 1726, global step 172700: 'train_loss' was not in top 1\n",
      "Epoch 1727, global step 172800: 'train_loss' was not in top 1\n",
      "Epoch 1728, global step 172900: 'train_loss' was not in top 1\n",
      "Epoch 1729, global step 173000: 'train_loss' was not in top 1\n",
      "Epoch 1730, global step 173100: 'train_loss' was not in top 1\n",
      "Epoch 1731, global step 173200: 'train_loss' was not in top 1\n",
      "Epoch 1732, global step 173300: 'train_loss' was not in top 1\n",
      "Epoch 1733, global step 173400: 'train_loss' was not in top 1\n",
      "Epoch 1734, global step 173500: 'train_loss' was not in top 1\n",
      "Epoch 1735, global step 173600: 'train_loss' was not in top 1\n",
      "Epoch 1736, global step 173700: 'train_loss' was not in top 1\n",
      "Epoch 1737, global step 173800: 'train_loss' was not in top 1\n",
      "Epoch 1738, global step 173900: 'train_loss' was not in top 1\n",
      "Epoch 1739, global step 174000: 'train_loss' was not in top 1\n",
      "Epoch 1740, global step 174100: 'train_loss' was not in top 1\n",
      "Epoch 1741, global step 174200: 'train_loss' was not in top 1\n",
      "Epoch 1742, global step 174300: 'train_loss' was not in top 1\n",
      "Epoch 1743, global step 174400: 'train_loss' was not in top 1\n",
      "Epoch 1744, global step 174500: 'train_loss' was not in top 1\n",
      "Epoch 1745, global step 174600: 'train_loss' was not in top 1\n",
      "Epoch 1746, global step 174700: 'train_loss' was not in top 1\n",
      "Epoch 1747, global step 174800: 'train_loss' was not in top 1\n",
      "Epoch 1748, global step 174900: 'train_loss' was not in top 1\n",
      "Epoch 1749, global step 175000: 'train_loss' was not in top 1\n",
      "Epoch 1750, global step 175100: 'train_loss' was not in top 1\n",
      "Epoch 1751, global step 175200: 'train_loss' was not in top 1\n",
      "Epoch 1752, global step 175300: 'train_loss' was not in top 1\n",
      "Epoch 1753, global step 175400: 'train_loss' was not in top 1\n",
      "Epoch 1754, global step 175500: 'train_loss' was not in top 1\n",
      "Epoch 1755, global step 175600: 'train_loss' was not in top 1\n",
      "Epoch 1756, global step 175700: 'train_loss' was not in top 1\n",
      "Epoch 1757, global step 175800: 'train_loss' was not in top 1\n",
      "Epoch 1758, global step 175900: 'train_loss' was not in top 1\n",
      "Epoch 1759, global step 176000: 'train_loss' was not in top 1\n",
      "Epoch 1760, global step 176100: 'train_loss' was not in top 1\n",
      "Epoch 1761, global step 176200: 'train_loss' was not in top 1\n",
      "Epoch 1762, global step 176300: 'train_loss' was not in top 1\n",
      "Epoch 1763, global step 176400: 'train_loss' was not in top 1\n",
      "Epoch 1764, global step 176500: 'train_loss' was not in top 1\n",
      "Epoch 1765, global step 176600: 'train_loss' was not in top 1\n",
      "Epoch 1766, global step 176700: 'train_loss' was not in top 1\n",
      "Epoch 1767, global step 176800: 'train_loss' was not in top 1\n",
      "Epoch 1768, global step 176900: 'train_loss' was not in top 1\n",
      "Epoch 1769, global step 177000: 'train_loss' was not in top 1\n",
      "Epoch 1770, global step 177100: 'train_loss' was not in top 1\n",
      "Epoch 1771, global step 177200: 'train_loss' was not in top 1\n",
      "Epoch 1772, global step 177300: 'train_loss' was not in top 1\n",
      "Epoch 1773, global step 177400: 'train_loss' was not in top 1\n",
      "Epoch 1774, global step 177500: 'train_loss' was not in top 1\n",
      "Epoch 1775, global step 177600: 'train_loss' was not in top 1\n",
      "Epoch 1776, global step 177700: 'train_loss' was not in top 1\n",
      "Epoch 1777, global step 177800: 'train_loss' was not in top 1\n",
      "Epoch 1778, global step 177900: 'train_loss' was not in top 1\n",
      "Epoch 1779, global step 178000: 'train_loss' was not in top 1\n",
      "Epoch 1780, global step 178100: 'train_loss' was not in top 1\n",
      "Epoch 1781, global step 178200: 'train_loss' was not in top 1\n",
      "Epoch 1782, global step 178300: 'train_loss' was not in top 1\n",
      "Epoch 1783, global step 178400: 'train_loss' was not in top 1\n",
      "Epoch 1784, global step 178500: 'train_loss' was not in top 1\n",
      "Epoch 1785, global step 178600: 'train_loss' was not in top 1\n",
      "Epoch 1786, global step 178700: 'train_loss' was not in top 1\n",
      "Epoch 1787, global step 178800: 'train_loss' was not in top 1\n",
      "Epoch 1788, global step 178900: 'train_loss' was not in top 1\n",
      "Epoch 1789, global step 179000: 'train_loss' was not in top 1\n",
      "Epoch 1790, global step 179100: 'train_loss' was not in top 1\n",
      "Epoch 1791, global step 179200: 'train_loss' was not in top 1\n",
      "Epoch 1792, global step 179300: 'train_loss' was not in top 1\n",
      "Epoch 1793, global step 179400: 'train_loss' was not in top 1\n",
      "Epoch 1794, global step 179500: 'train_loss' was not in top 1\n",
      "Epoch 1795, global step 179600: 'train_loss' was not in top 1\n",
      "Epoch 1796, global step 179700: 'train_loss' was not in top 1\n",
      "Epoch 1797, global step 179800: 'train_loss' was not in top 1\n",
      "Epoch 1798, global step 179900: 'train_loss' was not in top 1\n",
      "Epoch 1799, global step 180000: 'train_loss' was not in top 1\n",
      "Epoch 1800, global step 180100: 'train_loss' was not in top 1\n",
      "Epoch 1801, global step 180200: 'train_loss' was not in top 1\n",
      "Epoch 1802, global step 180300: 'train_loss' was not in top 1\n",
      "Epoch 1803, global step 180400: 'train_loss' was not in top 1\n",
      "Epoch 1804, global step 180500: 'train_loss' was not in top 1\n",
      "Epoch 1805, global step 180600: 'train_loss' was not in top 1\n",
      "Epoch 1806, global step 180700: 'train_loss' was not in top 1\n",
      "Epoch 1807, global step 180800: 'train_loss' was not in top 1\n",
      "Epoch 1808, global step 180900: 'train_loss' was not in top 1\n",
      "Epoch 1809, global step 181000: 'train_loss' was not in top 1\n",
      "Epoch 1810, global step 181100: 'train_loss' was not in top 1\n",
      "Epoch 1811, global step 181200: 'train_loss' was not in top 1\n",
      "Epoch 1812, global step 181300: 'train_loss' was not in top 1\n",
      "Epoch 1813, global step 181400: 'train_loss' was not in top 1\n",
      "Epoch 1814, global step 181500: 'train_loss' was not in top 1\n",
      "Epoch 1815, global step 181600: 'train_loss' was not in top 1\n",
      "Epoch 1816, global step 181700: 'train_loss' was not in top 1\n",
      "Epoch 1817, global step 181800: 'train_loss' was not in top 1\n",
      "Epoch 1818, global step 181900: 'train_loss' was not in top 1\n",
      "Epoch 1819, global step 182000: 'train_loss' was not in top 1\n",
      "Epoch 1820, global step 182100: 'train_loss' was not in top 1\n",
      "Epoch 1821, global step 182200: 'train_loss' was not in top 1\n",
      "Epoch 1822, global step 182300: 'train_loss' was not in top 1\n",
      "Epoch 1823, global step 182400: 'train_loss' was not in top 1\n",
      "Epoch 1824, global step 182500: 'train_loss' was not in top 1\n",
      "Epoch 1825, global step 182600: 'train_loss' was not in top 1\n",
      "Epoch 1826, global step 182700: 'train_loss' was not in top 1\n",
      "Epoch 1827, global step 182800: 'train_loss' was not in top 1\n",
      "Epoch 1828, global step 182900: 'train_loss' was not in top 1\n",
      "Epoch 1829, global step 183000: 'train_loss' was not in top 1\n",
      "Epoch 1830, global step 183100: 'train_loss' was not in top 1\n",
      "Epoch 1831, global step 183200: 'train_loss' was not in top 1\n",
      "Epoch 1832, global step 183300: 'train_loss' was not in top 1\n",
      "Epoch 1833, global step 183400: 'train_loss' was not in top 1\n",
      "Epoch 1834, global step 183500: 'train_loss' was not in top 1\n",
      "Epoch 1835, global step 183600: 'train_loss' was not in top 1\n",
      "Epoch 1836, global step 183700: 'train_loss' was not in top 1\n",
      "Epoch 1837, global step 183800: 'train_loss' was not in top 1\n",
      "Epoch 1838, global step 183900: 'train_loss' was not in top 1\n",
      "Epoch 1839, global step 184000: 'train_loss' was not in top 1\n",
      "Epoch 1840, global step 184100: 'train_loss' was not in top 1\n",
      "Epoch 1841, global step 184200: 'train_loss' was not in top 1\n",
      "Epoch 1842, global step 184300: 'train_loss' was not in top 1\n",
      "Epoch 1843, global step 184400: 'train_loss' was not in top 1\n",
      "Epoch 1844, global step 184500: 'train_loss' was not in top 1\n",
      "Epoch 1845, global step 184600: 'train_loss' was not in top 1\n",
      "Epoch 1846, global step 184700: 'train_loss' was not in top 1\n",
      "Epoch 1847, global step 184800: 'train_loss' was not in top 1\n",
      "Epoch 1848, global step 184900: 'train_loss' was not in top 1\n",
      "Epoch 1849, global step 185000: 'train_loss' was not in top 1\n",
      "Epoch 1850, global step 185100: 'train_loss' was not in top 1\n",
      "Epoch 1851, global step 185200: 'train_loss' was not in top 1\n",
      "Epoch 1852, global step 185300: 'train_loss' was not in top 1\n",
      "Epoch 1853, global step 185400: 'train_loss' was not in top 1\n",
      "Epoch 1854, global step 185500: 'train_loss' was not in top 1\n",
      "Epoch 1855, global step 185600: 'train_loss' was not in top 1\n",
      "Epoch 1856, global step 185700: 'train_loss' was not in top 1\n",
      "Epoch 1857, global step 185800: 'train_loss' was not in top 1\n",
      "Epoch 1858, global step 185900: 'train_loss' was not in top 1\n",
      "Epoch 1859, global step 186000: 'train_loss' was not in top 1\n",
      "Epoch 1860, global step 186100: 'train_loss' was not in top 1\n",
      "Epoch 1861, global step 186200: 'train_loss' was not in top 1\n",
      "Epoch 1862, global step 186300: 'train_loss' was not in top 1\n",
      "Epoch 1863, global step 186400: 'train_loss' was not in top 1\n",
      "Epoch 1864, global step 186500: 'train_loss' was not in top 1\n",
      "Epoch 1865, global step 186600: 'train_loss' was not in top 1\n",
      "Epoch 1866, global step 186700: 'train_loss' was not in top 1\n",
      "Epoch 1867, global step 186800: 'train_loss' was not in top 1\n",
      "Epoch 1868, global step 186900: 'train_loss' was not in top 1\n",
      "Epoch 1869, global step 187000: 'train_loss' was not in top 1\n",
      "Epoch 1870, global step 187100: 'train_loss' was not in top 1\n",
      "Epoch 1871, global step 187200: 'train_loss' was not in top 1\n",
      "Epoch 1872, global step 187300: 'train_loss' was not in top 1\n",
      "Epoch 1873, global step 187400: 'train_loss' was not in top 1\n",
      "Epoch 1874, global step 187500: 'train_loss' was not in top 1\n",
      "Epoch 1875, global step 187600: 'train_loss' was not in top 1\n",
      "Epoch 1876, global step 187700: 'train_loss' was not in top 1\n",
      "Epoch 1877, global step 187800: 'train_loss' was not in top 1\n",
      "Epoch 1878, global step 187900: 'train_loss' was not in top 1\n",
      "Epoch 1879, global step 188000: 'train_loss' was not in top 1\n",
      "Epoch 1880, global step 188100: 'train_loss' was not in top 1\n",
      "Epoch 1881, global step 188200: 'train_loss' was not in top 1\n",
      "Epoch 1882, global step 188300: 'train_loss' was not in top 1\n",
      "Epoch 1883, global step 188400: 'train_loss' was not in top 1\n",
      "Epoch 1884, global step 188500: 'train_loss' was not in top 1\n",
      "Epoch 1885, global step 188600: 'train_loss' was not in top 1\n",
      "Epoch 1886, global step 188700: 'train_loss' was not in top 1\n",
      "Epoch 1887, global step 188800: 'train_loss' was not in top 1\n",
      "Epoch 1888, global step 188900: 'train_loss' was not in top 1\n",
      "Epoch 1889, global step 189000: 'train_loss' was not in top 1\n",
      "Epoch 1890, global step 189100: 'train_loss' was not in top 1\n",
      "Epoch 1891, global step 189200: 'train_loss' was not in top 1\n",
      "Epoch 1892, global step 189300: 'train_loss' was not in top 1\n",
      "Epoch 1893, global step 189400: 'train_loss' was not in top 1\n",
      "Epoch 1894, global step 189500: 'train_loss' was not in top 1\n",
      "Epoch 1895, global step 189600: 'train_loss' was not in top 1\n",
      "Epoch 1896, global step 189700: 'train_loss' was not in top 1\n",
      "Epoch 1897, global step 189800: 'train_loss' was not in top 1\n",
      "Epoch 1898, global step 189900: 'train_loss' was not in top 1\n",
      "Epoch 1899, global step 190000: 'train_loss' was not in top 1\n",
      "Epoch 1900, global step 190100: 'train_loss' was not in top 1\n",
      "Epoch 1901, global step 190200: 'train_loss' was not in top 1\n",
      "Epoch 1902, global step 190300: 'train_loss' was not in top 1\n",
      "Epoch 1903, global step 190400: 'train_loss' was not in top 1\n",
      "Epoch 1904, global step 190500: 'train_loss' was not in top 1\n",
      "Epoch 1905, global step 190600: 'train_loss' was not in top 1\n",
      "Epoch 1906, global step 190700: 'train_loss' was not in top 1\n",
      "Epoch 1907, global step 190800: 'train_loss' was not in top 1\n",
      "Epoch 1908, global step 190900: 'train_loss' was not in top 1\n",
      "Epoch 1909, global step 191000: 'train_loss' was not in top 1\n",
      "Epoch 1910, global step 191100: 'train_loss' was not in top 1\n",
      "Epoch 1911, global step 191200: 'train_loss' was not in top 1\n",
      "Epoch 1912, global step 191300: 'train_loss' was not in top 1\n",
      "Epoch 1913, global step 191400: 'train_loss' was not in top 1\n",
      "Epoch 1914, global step 191500: 'train_loss' was not in top 1\n",
      "Epoch 1915, global step 191600: 'train_loss' was not in top 1\n",
      "Epoch 1916, global step 191700: 'train_loss' was not in top 1\n",
      "Epoch 1917, global step 191800: 'train_loss' was not in top 1\n",
      "Epoch 1918, global step 191900: 'train_loss' was not in top 1\n",
      "Epoch 1919, global step 192000: 'train_loss' was not in top 1\n",
      "Epoch 1920, global step 192100: 'train_loss' was not in top 1\n",
      "Epoch 1921, global step 192200: 'train_loss' was not in top 1\n",
      "Epoch 1922, global step 192300: 'train_loss' was not in top 1\n",
      "Epoch 1923, global step 192400: 'train_loss' was not in top 1\n",
      "Epoch 1924, global step 192500: 'train_loss' was not in top 1\n",
      "Epoch 1925, global step 192600: 'train_loss' was not in top 1\n",
      "Epoch 1926, global step 192700: 'train_loss' was not in top 1\n",
      "Epoch 1927, global step 192800: 'train_loss' was not in top 1\n",
      "Epoch 1928, global step 192900: 'train_loss' was not in top 1\n",
      "Epoch 1929, global step 193000: 'train_loss' was not in top 1\n",
      "Epoch 1930, global step 193100: 'train_loss' was not in top 1\n",
      "Epoch 1931, global step 193200: 'train_loss' was not in top 1\n",
      "Epoch 1932, global step 193300: 'train_loss' was not in top 1\n",
      "Epoch 1933, global step 193400: 'train_loss' was not in top 1\n",
      "Epoch 1934, global step 193500: 'train_loss' was not in top 1\n",
      "Epoch 1935, global step 193600: 'train_loss' was not in top 1\n",
      "Epoch 1936, global step 193700: 'train_loss' was not in top 1\n",
      "Epoch 1937, global step 193800: 'train_loss' was not in top 1\n",
      "Epoch 1938, global step 193900: 'train_loss' was not in top 1\n",
      "Epoch 1939, global step 194000: 'train_loss' was not in top 1\n",
      "Epoch 1940, global step 194100: 'train_loss' was not in top 1\n",
      "Epoch 1941, global step 194200: 'train_loss' was not in top 1\n",
      "Epoch 1942, global step 194300: 'train_loss' was not in top 1\n",
      "Epoch 1943, global step 194400: 'train_loss' was not in top 1\n",
      "Epoch 1944, global step 194500: 'train_loss' was not in top 1\n",
      "Epoch 1945, global step 194600: 'train_loss' was not in top 1\n",
      "Epoch 1946, global step 194700: 'train_loss' was not in top 1\n",
      "Epoch 1947, global step 194800: 'train_loss' was not in top 1\n",
      "Epoch 1948, global step 194900: 'train_loss' was not in top 1\n",
      "Epoch 1949, global step 195000: 'train_loss' was not in top 1\n",
      "Epoch 1950, global step 195100: 'train_loss' was not in top 1\n",
      "Epoch 1951, global step 195200: 'train_loss' was not in top 1\n",
      "Epoch 1952, global step 195300: 'train_loss' was not in top 1\n",
      "Epoch 1953, global step 195400: 'train_loss' was not in top 1\n",
      "Epoch 1954, global step 195500: 'train_loss' was not in top 1\n",
      "Epoch 1955, global step 195600: 'train_loss' was not in top 1\n",
      "Epoch 1956, global step 195700: 'train_loss' was not in top 1\n",
      "Epoch 1957, global step 195800: 'train_loss' was not in top 1\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "The mean prediction is not stored in the forecast data; the median is being returned instead. This behaviour may change in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past Dynamic Features Training Shape: (38, 2790)\n",
      "Past Dynamic Features Test Shape: (38, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.tft import TemporalFusionTransformerEstimator\n",
    "from gluonts.transform.feature import MissingValueImputation\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "                                   \n",
    "# Assuming df is your DataFrame with the data\n",
    "target_column = 'BTC-USD_High'  # Replace with your target column name\n",
    "\n",
    "# Ensure the DataFrame's index is a datetime index and set the frequency explicitly if needed\n",
    "df.index = pd.to_datetime(df.index)\n",
    "freq = \"D\"  # Set the frequency of your data, e.g., 'D' for daily. Adjust as needed.\n",
    "df = df.asfreq(freq)\n",
    "\n",
    "# Define the prediction length\n",
    "prediction_length = 1  # Set your prediction length\n",
    "\n",
    "# Select dynamic features from the DataFrame, excluding the target column\n",
    "past_dynamic_feature_columns = df.columns.drop(target_column)  # This excludes the target column\n",
    "\n",
    "# Extract dynamic features as a numpy array\n",
    "past_dynamic_features = df[past_dynamic_feature_columns].values.transpose()\n",
    "\n",
    "# Assuming all dynamic features are known in the future, adjust the dimensions accordingly\n",
    "past_dynamic_dims  = [1] * len(past_dynamic_feature_columns)  # Adjust based on actual dynamic features\n",
    "\n",
    "# Make sure the lengths match when creating ListDataset\n",
    "training_data = ListDataset([\n",
    "    {\n",
    "        \"start\": df.index[0],\n",
    "        \"target\": df[target_column][:-prediction_length],\n",
    "        \"past_feat_dynamic_real\": past_dynamic_features[:, :-prediction_length]\n",
    "    }\n",
    "], freq=freq)\n",
    "\n",
    "# Adjust the slicing for dynamic features for the test dataset to ensure correct dimensions\n",
    "test_past_dynamic_features_sliced = past_dynamic_features[:, -prediction_length:]\n",
    "\n",
    "test_data = ListDataset([\n",
    "    {\n",
    "        \"start\": df.index[-prediction_length],\n",
    "        \"target\": df[target_column][-prediction_length:].values,\n",
    "        \"past_feat_dynamic_real\": test_past_dynamic_features_sliced\n",
    "    }\n",
    "], freq=freq)\n",
    "\n",
    "# Initialize the Temporal Fusion Transformer Estimator\n",
    "estimator = TemporalFusionTransformerEstimator(\n",
    "    freq=freq,\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=7,  # Optional: adjust based on your needs\n",
    "    num_heads=32,\n",
    "    hidden_dim=1024,\n",
    "    variable_dim=1024,\n",
    "    past_dynamic_dims= past_dynamic_dims,\n",
    "    quantiles=[0.1, 0.5, 0.9],  # Specifying the quantiles for forecasting\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-08,\n",
    "    dropout_rate=0.1,\n",
    "    patience=10,\n",
    "    batch_size=128,\n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs={'max_epochs': 5000},  # Adjust 'gpus' based on your setup\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "predictor = estimator.train(training_data)\n",
    "\n",
    "# Debugging: Print dimensions to verify alignment\n",
    "print(f\"Past Dynamic Features Training Shape: {past_dynamic_features[:, :-prediction_length].shape}\")\n",
    "print(f\"Past Dynamic Features Test Shape: {test_past_dynamic_features_sliced.shape}\")\n",
    "\n",
    "# Collect actual and predicted values for evaluation, including percentiles\n",
    "actuals = df[target_column][-prediction_length:].values\n",
    "mean_predictions = []\n",
    "p10_predictions = []\n",
    "p50_predictions = []\n",
    "p90_predictions = []\n",
    "\n",
    "for forecast in predictor.predict(test_data):\n",
    "    mean_predictions.append(forecast.mean)\n",
    "    p10_predictions.append(forecast.quantile(0.1))\n",
    "    p50_predictions.append(forecast.quantile(0.5))  # Median\n",
    "    p90_predictions.append(forecast.quantile(0.9))\n",
    "\n",
    "# Convert lists to numpy arrays for slicing\n",
    "mean_predictions = np.array(mean_predictions).flatten()[:prediction_length]\n",
    "p10_predictions = np.array(p10_predictions).flatten()[:prediction_length]\n",
    "p50_predictions = np.array(p50_predictions).flatten()[:prediction_length]\n",
    "p90_predictions = np.array(p90_predictions).flatten()[:prediction_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5edfd4f-da3d-4ba5-ac72-637c722c6442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame with the data, and it's sorted by the index (date)\n",
    "target_column = 'BTC-USD_High'  # Ensure this matches your actual target column name\n",
    "prediction_length = 1\n",
    "# Assuming the DataFrame's index is a datetime index and sorted\n",
    "end_training = df.index[-1]  # Assuming prediction_length is defined earlier\n",
    "\n",
    "# Ensure forecast_start_date is a datetime object and exists in df.index\n",
    "forecast_start_date = end_training \n",
    "\n",
    "# Plot the forecast and actual values starting from the forecast start date\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual values from the start of the forecast\n",
    "actuals_start_index = df.index.get_loc(forecast_start_date)\n",
    "plt.plot(df.index[actuals_start_index:], df[target_column][actuals_start_index:], label=\"True values\", color=\"black\")\n",
    "\n",
    "# Assuming mean_predictions, p10_predictions, p50_predictions, p90_predictions are defined from the forecasting model\n",
    "# Plot forecast values\n",
    "forecast_index = pd.date_range(start=forecast_start_date, periods=prediction_length, freq=freq)  # freq should be defined as per your data's frequency\n",
    "plt.plot(forecast_index, mean_predictions, color='red', linestyle='--', label=\"Forecast (mean)\")\n",
    "plt.fill_between(forecast_index, p10_predictions, p90_predictions, color='red', alpha=0.3, label=\"P10-P90 interval\")\n",
    "plt.fill_between(forecast_index, p10_predictions, p50_predictions, color='red', alpha=0.5, label=\"P10-P50 interval\")\n",
    "plt.fill_between(forecast_index, p50_predictions, p90_predictions, color='red', alpha=0.5, label=\"P50-P90 interval\")\n",
    "\n",
    "# Add a vertical line and other plot elements\n",
    "plt.axvline(x=forecast_start_date, color='blue', linestyle='--', label='Start of forecast')\n",
    "plt.legend(loc=\"upper left\", fontsize=\"large\")\n",
    "plt.title('Forecast vs Actual Values from Forecast Start')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960df258-1313-46e2-92ba-0d8b39afa15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_High</th>\n",
       "      <th>BTC-USD_Low</th>\n",
       "      <th>AdrBalNtv0.01Cnt</th>\n",
       "      <th>AdrBalNtv0.1Cnt</th>\n",
       "      <th>AdrBalNtv1Cnt</th>\n",
       "      <th>AdrBalNtv10Cnt</th>\n",
       "      <th>BlkSizeMeanByte</th>\n",
       "      <th>CapRealUSD</th>\n",
       "      <th>FeeByteMeanNtv</th>\n",
       "      <th>FlowInExNtv</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC-USD_High_SMA_5</th>\n",
       "      <th>BTC-USD_Low_SMA_5</th>\n",
       "      <th>BTC-USD_High_SMA_10</th>\n",
       "      <th>BTC-USD_Low_SMA_10</th>\n",
       "      <th>BTC-USD_High_SMA_20</th>\n",
       "      <th>BTC-USD_Low_SMA_20</th>\n",
       "      <th>BTC-USD_High_SMA_50</th>\n",
       "      <th>BTC-USD_Low_SMA_50</th>\n",
       "      <th>BTC-USD_High_SMA_100</th>\n",
       "      <th>BTC-USD_Low_SMA_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-05</th>\n",
       "      <td>43494.25</td>\n",
       "      <td>42264.816406</td>\n",
       "      <td>12605783.0</td>\n",
       "      <td>4571143.0</td>\n",
       "      <td>1019671.0</td>\n",
       "      <td>154513.0</td>\n",
       "      <td>1.415660e+06</td>\n",
       "      <td>4.487452e+11</td>\n",
       "      <td>2.925980e-07</td>\n",
       "      <td>23439.165199</td>\n",
       "      <td>...</td>\n",
       "      <td>43323.498437</td>\n",
       "      <td>42398.796875</td>\n",
       "      <td>43247.251953</td>\n",
       "      <td>42195.082422</td>\n",
       "      <td>42456.619531</td>\n",
       "      <td>41243.237891</td>\n",
       "      <td>43686.311953</td>\n",
       "      <td>42091.993438</td>\n",
       "      <td>41291.485234</td>\n",
       "      <td>39872.907578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_High   BTC-USD_Low  AdrBalNtv0.01Cnt  AdrBalNtv0.1Cnt  \\\n",
       "2024-02-05      43494.25  42264.816406        12605783.0        4571143.0   \n",
       "\n",
       "            AdrBalNtv1Cnt  AdrBalNtv10Cnt  BlkSizeMeanByte    CapRealUSD  \\\n",
       "2024-02-05      1019671.0        154513.0     1.415660e+06  4.487452e+11   \n",
       "\n",
       "            FeeByteMeanNtv   FlowInExNtv  ...  BTC-USD_High_SMA_5  \\\n",
       "2024-02-05    2.925980e-07  23439.165199  ...        43323.498437   \n",
       "\n",
       "            BTC-USD_Low_SMA_5  BTC-USD_High_SMA_10  BTC-USD_Low_SMA_10  \\\n",
       "2024-02-05       42398.796875         43247.251953        42195.082422   \n",
       "\n",
       "            BTC-USD_High_SMA_20  BTC-USD_Low_SMA_20  BTC-USD_High_SMA_50  \\\n",
       "2024-02-05         42456.619531        41243.237891         43686.311953   \n",
       "\n",
       "            BTC-USD_Low_SMA_50  BTC-USD_High_SMA_100  BTC-USD_Low_SMA_100  \n",
       "2024-02-05        42091.993438          41291.485234         39872.907578  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_row = df.iloc[-1:, :]\n",
    "last_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53cc2ba-d3a8-4bfe-9945-bc79f261cabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43494.25], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p50_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0fd538-c47b-4b5a-9131-a6f5995b01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Mean Predictions:\n",
      "MAE: 0.00\n",
      "RMSE: 0.00\n",
      "MAPE: 0.00%\n",
      "sMAPE: 0.00%\n",
      "Percentage of Actuals within P10-P90 Interval: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate sMAPE\n",
    "def calculate_smape(forecasts, actuals):\n",
    "    return 100 * np.mean(2 * np.abs(forecasts - actuals) / (np.abs(actuals) + np.abs(forecasts)))\n",
    "\n",
    "# Calculate standard evaluation metrics for mean predictions\n",
    "mae = np.mean(np.abs(mean_predictions - actuals))\n",
    "rmse = np.sqrt(np.mean(np.square(mean_predictions - actuals)))\n",
    "mape = np.mean(np.abs((mean_predictions - actuals) / actuals)) * 100\n",
    "smape = calculate_smape(mean_predictions, actuals)\n",
    "\n",
    "# Calculate the percentage of actuals within the 10th to 90th percentile range\n",
    "within_range = np.sum((actuals >= p10_predictions) & (actuals <= p90_predictions)) / len(actuals) * 100\n",
    "\n",
    "print(\"Evaluation Metrics for Mean Predictions:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"sMAPE: {smape:.2f}%\")\n",
    "print(f\"Percentage of Actuals within P10-P90 Interval: {within_range:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa71034-caf4-433e-ae72-05fa5395ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to dudley_high.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define a path to save the model\n",
    "model_save_path = 'dudley_high.pth'\n",
    "\n",
    "# Assuming 'predictor' is the trained model from DeepAREstimator\n",
    "torch.save(predictor, model_save_path)\n",
    "\n",
    "print(f'Model saved to {model_save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec76915-33c0-402f-96dc-ed8e1641c23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
